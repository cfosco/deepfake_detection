{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to motion magnify sets of videos\n",
    "\n",
    "Uses learned motion mag: https://people.csail.mit.edu/tiam/deepmag/deepmag.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import setproctitle\n",
    "from configobj import ConfigObj\n",
    "from validate import Validator\n",
    "\n",
    "sys.path.append(\"../deep_motion_mag/\")\n",
    "\n",
    "from magnet import MagNet3Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 11 13:07:55 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 23%   34C    P8     9W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   32C    P8     9W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            Off  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 23%   31C    P8     9W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8     9W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# EXP_NAME=\"test\"\n",
    "# VIDEO=1003254\n",
    "# AMPLIFICATION_FACTOR=10\n",
    "# DYNAMIC_MODE=\"no\"\n",
    "# OUT_DIR=data/output/\"$VIDEO\"_\"$EXP_NAME\"_\"$AMPLIFICATION_FACTOR\"\n",
    "# VID_DIR=data/vids/\"$VIDEO\"\n",
    "# OUT_DIR=data/output/\"$VIDEO\"\n",
    "# if [ ! -d \"$OUT_DIR\" ]; then\n",
    "#     mkdir -p \"$OUT_DIR\"\n",
    "# fi\n",
    "\n",
    "# FLAGS=\"--phase=run --vid_dir=$VID_DIR --out_dir=$OUT_DIR --amplification_factor=$AMPLIFICATION_FACTOR\"\n",
    "# if [ \"$DYNAMIC_MODE\" = yes ] ; then\n",
    "#     FLAGS=\"$FLAGS\"\" --velocity_mag\"\n",
    "# fi\n",
    "# ../deep_motion_mag/main.py --config_file=configs/\"$EXP_NAME\".conf \\\n",
    "#     $FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# sh ../deep_motion_mag/run_on_test_videos.sh test1 1003254 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amplification_factor': 3,\n",
      " 'config_file': '../deep_motion_mag/configs/o3f_hmhm2_bg_qnoise_mix4_nl_n_t_ds3.conf',\n",
      " 'config_spec': '../deep_motion_mag/configs/configspec.conf',\n",
      " 'fh': 1,\n",
      " 'filter_type': 'DifferenceOfIIR',\n",
      " 'fl': 0.5,\n",
      " 'frame_ext': 'jpg',\n",
      " 'fs': 30,\n",
      " 'n_filter_tap': 2,\n",
      " 'out_dir': '../../deepfake_data/fb_dfd_release_0.1_final/method_A_frames_mm/1320815_1573558_A_002.mp4',\n",
      " 'phase': 'run',\n",
      " 'velocity_mag': True,\n",
      " 'vid_dir': '../../deepfake_data/fb_dfd_release_0.1_final/method_A_frames/1320815_1573558_A_002.mp4'}\n"
     ]
    }
   ],
   "source": [
    "def run_motion_mag(args):\n",
    "    configspec = ConfigObj(args.config_spec, raise_errors=True)\n",
    "    config = ConfigObj(args.config_file,\n",
    "                       configspec=configspec,\n",
    "                       raise_errors=True,\n",
    "                       file_error=True)\n",
    "    # Validate to get all the default values.\n",
    "    config.validate(Validator())\n",
    "    if not os.path.exists(config['exp_dir']):\n",
    "        # checkpoint directory.\n",
    "        os.makedirs(os.path.join(config['exp_dir'], 'checkpoint'))\n",
    "        # Tensorboard logs directory.\n",
    "        os.makedirs(os.path.join(config['exp_dir'], 'logs'))\n",
    "        # default output directory for this experiment.\n",
    "        os.makedirs(os.path.join(config['exp_dir'], 'sample'))\n",
    "    network_type = config['architecture']['network_arch']\n",
    "    exp_name = config['exp_name']\n",
    "    setproctitle.setproctitle('{}_{}_{}' \\\n",
    "                              .format(args.phase, network_type, exp_name))\n",
    "    tfconfig = tf.ConfigProto(allow_soft_placement=True,\n",
    "                              log_device_placement=False)\n",
    "    tfconfig.gpu_options.allow_growth = True\n",
    "\n",
    "    with tf.Session(config=tfconfig) as sess:\n",
    "        model = MagNet3Frames(sess, exp_name, config['architecture'])\n",
    "        checkpoint = '../deep_motion_mag/'+config['training']['checkpoint_dir']\n",
    "        if args.phase == 'train':\n",
    "            train_config = config['training']\n",
    "            if not os.path.exists('../deep_motion_mag/'+train_config['checkpoint_dir']):\n",
    "                os.makedirs('../deep_motion_mag/'+train_config['checkpoint_dir'])\n",
    "            model.train(train_config)\n",
    "        elif args.phase == 'run':\n",
    "            model.run(checkpoint,\n",
    "                      args.vid_dir,\n",
    "                      args.frame_ext,\n",
    "                      args.out_dir,\n",
    "                      args.amplification_factor,\n",
    "                      args.velocity_mag)\n",
    "        elif args.phase == 'run_temporal':\n",
    "            model.run_temporal(checkpoint,\n",
    "                               args.vid_dir,\n",
    "                               args.frame_ext,\n",
    "                               args.out_dir,\n",
    "                               args.amplification_factor,\n",
    "                               args.fl,\n",
    "                               args.fh,\n",
    "                               args.fs,\n",
    "                               args.n_filter_tap,\n",
    "                               args.filter_type)\n",
    "        else:\n",
    "            raise ValueError('Invalid phase argument. '\n",
    "                             'Expected [\"train\", \"run\", \"run_temporal\"], '\n",
    "                             'got ' + args.phase)\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "exp_name= 'o3f_hmhm2_bg_qnoise_mix4_nl_n_t_ds3'\n",
    "phase = 'run'\n",
    "config_file = '../deep_motion_mag/configs/'+exp_name+'.conf'\n",
    "config_spec = '../deep_motion_mag/configs/configspec.conf'\n",
    "vid_dir = '../../deepfake_data/fb_dfd_release_0.1_final/method_A_frames/1320815_1573558_A_002.mp4'\n",
    "frame_ext = 'jpg'\n",
    "out_dir = '../../deepfake_data/fb_dfd_release_0.1_final/method_A_frames_mm/1320815_1573558_A_002.mp4'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "amplification_factor = 3\n",
    "velocity_mag = True\n",
    "fl = 0.5\n",
    "fh = 1\n",
    "fs = 30\n",
    "n_filter_tap = 2 \n",
    "filter_type = 'DifferenceOfIIR'\n",
    "\n",
    "\n",
    "class Parser:        \n",
    "    def add_argument(self, name, dest='var', default=None, help='', required=True, type='', action=''):\n",
    "        exec(\"self.\"+dest+\" = default\")\n",
    "parser = Parser()\n",
    "        \n",
    "parser.add_argument('--phase', dest='phase', default=phase,\n",
    "                    help='train, test, run, interactive')\n",
    "parser.add_argument('--config_file', dest='config_file', required=True, default = config_file,\n",
    "                    help='path to config file')\n",
    "parser.add_argument('--config_spec', dest='config_spec', default=config_spec,\n",
    "                    help='path to config spec file')\n",
    "\n",
    "# for inference\n",
    "parser.add_argument('--vid_dir', dest='vid_dir', default=vid_dir,\n",
    "                    help='Video folder to run the network on.')\n",
    "parser.add_argument('--frame_ext', dest='frame_ext', default=frame_ext,\n",
    "                    help='Video frame file extension.')\n",
    "parser.add_argument('--out_dir', dest='out_dir', default=out_dir,\n",
    "                    help='Output folder of the video run.')\n",
    "parser.add_argument('--amplification_factor', dest='amplification_factor',\n",
    "                    type=float, default=amplification_factor,\n",
    "                    help='Magnification factor for inference.')\n",
    "parser.add_argument('--velocity_mag', dest='velocity_mag', action='store_true', default=velocity_mag,\n",
    "                    help='Whether to do velocity magnification.')\n",
    "\n",
    "# For temporal operation.\n",
    "parser.add_argument('--fl', dest='fl', type=float, default=fl,\n",
    "                    help='Low cutoff Frequency.')\n",
    "parser.add_argument('--fh', dest='fh', type=float, default=fh,\n",
    "                    help='High cutoff Frequency.')\n",
    "parser.add_argument('--fs', dest='fs', type=float, default=fs,\n",
    "                    help='Sampling rate.')\n",
    "parser.add_argument('--n_filter_tap', dest='n_filter_tap', type=int, default=n_filter_tap,\n",
    "                    help='Number of filter tap required.')\n",
    "parser.add_argument('--filter_type', dest='filter_type', type=str, default=filter_type,\n",
    "                    help='Type of filter to use, must be Butter or FIR.')\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(vars(parser))\n",
    "\n",
    "# run_motion_mag(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnifying vids in ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops\n",
      "running motion mag for vid: 1941250_1916010_B_002.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1941250_1916010_B_002.mp4\n",
      "\n",
      "WARNING:tensorflow:From ../deep_motion_mag/magnet.py:294: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ../deep_motion_mag/magnet.py:313: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87f1dc25c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87f1dc25c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87f1dc25c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87f1dc25c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87f1dc2780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87f1dc2780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87f1dc2780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87f1dc2780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100f6eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100f6eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100f6eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100f6eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891015af60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891015af60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891015af60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891015af60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100ed710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100ed710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100ed710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100ed710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8910157048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8910157048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8910157048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8910157048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891015aef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891015aef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891015aef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891015aef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100844a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100844a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100844a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89100844a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f89107c2b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891012e3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891012e3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891012e3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f891012e3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021c240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021c240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021ca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021ca90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021ca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021ca90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8910093fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8910093fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8910093fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8910093fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8860178898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8860178898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8860178898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8860178898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021c860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021c860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021c860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886021c860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88601dc7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88601dc7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88601dc7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88601dc7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88601dc3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88601dc3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88601dc3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88601dc3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600fd128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600fd128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600fd128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600fd128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From ../deep_motion_mag/magnet.py:106: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600cb9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600cb9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600cb9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600cb9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600a3d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600a3d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600a3d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600a3d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009ea20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009ea20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009ea20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009ea20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009eb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009eb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009eb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009eb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600734e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600734e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600734e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f88600734e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886004a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886004a550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886004a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886004a550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a7e4278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a7e4278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a7e4278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a7e4278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a7e46d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a7e46d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a7e46d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a7e46d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a79def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a79def0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a79def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a79def0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a79d3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a79d3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a79d3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a79d3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a755f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a755f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a755f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a755f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a752e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a752e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a752e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a752e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6fe5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6fe5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6fe5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6fe5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009e908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009e908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009e908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f886009e908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a691780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a691780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a691780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a691780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6917b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6917b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6917b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6917b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884ea427f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884ea427f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884ea427f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884ea427f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6df2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6df2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6df2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6df2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6fb898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6fb898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6fb898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f885a6fb898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884e9ee208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884e9ee208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884e9ee208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884e9ee208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884e9ee668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884e9ee668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884e9ee668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f884e9ee668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From ../deep_motion_mag/magnet.py:330: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From ../deep_motion_mag/magnet.py:398: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../deep_motion_mag/magnet.py:399: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      " [*] Reading checkpoint...\n",
      "WARNING:tensorflow:From /afs/csail.mit.edu/u/c/cfosco/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../deep_motion_mag/data/training/o3f_hmhm2_bg_qnoise_mix4_nl_n_t_ds3/checkpoint/o3f_hmhm2_bg_qnoise_mix4_nl_n_t_ds3-259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from ckpt: ../deep_motion_mag/data/training/o3f_hmhm2_bg_qnoise_mix4_nl_n_t_ds3/checkpoint/o3f_hmhm2_bg_qnoise_mix4_nl_n_t_ds3-259002\n",
      "[*] Load Success\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   0%|          | 1/225 [00:01<06:31,  1.75s/it]\u001b[A\n",
      "Applying IIR:   2%|         | 4/225 [00:01<04:33,  1.24s/it]\u001b[A\n",
      "Applying IIR:   3%|         | 7/225 [00:01<03:11,  1.14it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 11/225 [00:02<02:13,  1.60it/s]\u001b[A\n",
      "Applying IIR:   6%|         | 14/225 [00:02<01:34,  2.23it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 17/225 [00:02<01:08,  3.05it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 20/225 [00:02<00:49,  4.13it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 23/225 [00:02<00:36,  5.53it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 26/225 [00:02<00:27,  7.24it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 29/225 [00:02<00:21,  9.05it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 32/225 [00:02<00:17, 11.18it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 35/225 [00:03<00:13, 13.62it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/225 [00:03<00:11, 16.39it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/225 [00:03<00:09, 18.51it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 45/225 [00:03<00:08, 20.29it/s]\u001b[A\n",
      "Applying IIR:  21%|       | 48/225 [00:03<00:07, 22.27it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 51/225 [00:03<00:07, 23.95it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:03<00:06, 24.62it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:03<00:06, 25.95it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 60/225 [00:03<00:06, 26.74it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 64/225 [00:04<00:05, 27.46it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 67/225 [00:04<00:05, 26.53it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 70/225 [00:04<00:05, 27.22it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 74/225 [00:04<00:05, 28.56it/s]\u001b[A\n",
      "Applying IIR:  34%|      | 77/225 [00:04<00:05, 26.67it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 80/225 [00:04<00:05, 26.22it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 83/225 [00:04<00:05, 26.53it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 86/225 [00:04<00:05, 26.55it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 89/225 [00:05<00:05, 27.10it/s]\u001b[A\n",
      "Applying IIR:  41%|      | 92/225 [00:05<00:04, 27.39it/s]\u001b[A\n",
      "Applying IIR:  42%|     | 95/225 [00:05<00:04, 27.66it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 98/225 [00:05<00:04, 27.26it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 101/225 [00:05<00:04, 26.06it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 104/225 [00:05<00:04, 26.72it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 107/225 [00:05<00:04, 27.25it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 110/225 [00:05<00:04, 27.24it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 113/225 [00:05<00:04, 25.72it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 116/225 [00:06<00:04, 26.05it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 119/225 [00:06<00:03, 26.57it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 122/225 [00:06<00:03, 26.98it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 125/225 [00:06<00:03, 26.56it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 128/225 [00:06<00:03, 26.56it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 131/225 [00:06<00:03, 27.06it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 134/225 [00:06<00:03, 26.63it/s]\u001b[A\n",
      "Applying IIR:  61%|    | 137/225 [00:06<00:03, 27.27it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 140/225 [00:06<00:03, 27.83it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 144/225 [00:07<00:02, 29.22it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 147/225 [00:07<00:02, 27.92it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 150/225 [00:07<00:02, 27.93it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 153/225 [00:07<00:02, 28.02it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 156/225 [00:07<00:02, 25.85it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 159/225 [00:07<00:02, 24.04it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 162/225 [00:07<00:02, 23.74it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 165/225 [00:07<00:02, 24.65it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 168/225 [00:08<00:02, 25.83it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 171/225 [00:08<00:02, 26.56it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 175/225 [00:08<00:01, 27.60it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 178/225 [00:08<00:01, 28.26it/s]\u001b[A\n",
      "Applying IIR:  81%|  | 182/225 [00:08<00:01, 28.78it/s]\u001b[A\n",
      "Applying IIR:  82%| | 185/225 [00:08<00:01, 28.31it/s]\u001b[A\n",
      "Applying IIR:  84%| | 188/225 [00:08<00:01, 26.79it/s]\u001b[A\n",
      "Applying IIR:  85%| | 191/225 [00:08<00:01, 25.99it/s]\u001b[A\n",
      "Applying IIR:  86%| | 194/225 [00:08<00:01, 26.77it/s]\u001b[A\n",
      "Applying IIR:  88%| | 198/225 [00:09<00:00, 27.66it/s]\u001b[A\n",
      "Applying IIR:  89%| | 201/225 [00:09<00:00, 25.54it/s]\u001b[A\n",
      "Applying IIR:  91%| | 204/225 [00:09<00:00, 25.10it/s]\u001b[A\n",
      "Applying IIR:  92%|| 207/225 [00:09<00:00, 25.22it/s]\u001b[A\n",
      "Applying IIR:  93%|| 210/225 [00:09<00:00, 26.13it/s]\u001b[A\n",
      "Applying IIR:  95%|| 213/225 [00:09<00:00, 26.73it/s]\u001b[A\n",
      "Applying IIR:  96%|| 216/225 [00:09<00:00, 26.30it/s]\u001b[A\n",
      "Applying IIR:  97%|| 219/225 [00:09<00:00, 26.66it/s]\u001b[A\n",
      "Applying IIR:  99%|| 222/225 [00:10<00:00, 24.42it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:10<00:00, 22.15it/s]\u001b[A\n",
      "  5%|         | 1/21 [00:15<05:08, 15.43s/it]\n",
      "Applying IIR:   0%|          | 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   2%|         | 4/221 [00:00<00:06, 31.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1255229_1916010_B_003.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1255229_1916010_B_003.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 7/221 [00:00<00:07, 30.29it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 10/221 [00:00<00:07, 28.10it/s]\u001b[A\n",
      "Applying IIR:   6%|         | 13/221 [00:00<00:07, 27.42it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 16/221 [00:00<00:07, 27.26it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 19/221 [00:00<00:07, 27.02it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 22/221 [00:00<00:07, 26.75it/s]\u001b[A\n",
      "Applying IIR:  11%|        | 25/221 [00:00<00:07, 26.93it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 28/221 [00:01<00:06, 27.78it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 31/221 [00:01<00:07, 26.14it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 34/221 [00:01<00:07, 24.87it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 37/221 [00:01<00:07, 25.83it/s]\u001b[A\n",
      "Applying IIR:  18%|        | 40/221 [00:01<00:07, 25.46it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 43/221 [00:01<00:07, 25.08it/s]\u001b[A\n",
      "Applying IIR:  21%|        | 46/221 [00:01<00:07, 24.73it/s]\u001b[A\n",
      "Applying IIR:  22%|       | 49/221 [00:01<00:06, 24.94it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 52/221 [00:01<00:06, 25.78it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 55/221 [00:02<00:06, 26.57it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 59/221 [00:02<00:06, 26.94it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 62/221 [00:02<00:05, 27.18it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 65/221 [00:02<00:05, 27.73it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 69/221 [00:02<00:05, 29.13it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 73/221 [00:02<00:04, 30.25it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 77/221 [00:02<00:04, 29.72it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 81/221 [00:02<00:04, 30.56it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 85/221 [00:03<00:04, 29.73it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 88/221 [00:03<00:04, 28.00it/s]\u001b[A\n",
      "Applying IIR:  41%|      | 91/221 [00:03<00:04, 27.34it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 94/221 [00:03<00:04, 27.77it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 97/221 [00:03<00:04, 27.94it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 100/221 [00:03<00:04, 27.56it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 103/221 [00:03<00:04, 27.85it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 106/221 [00:03<00:04, 27.11it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 109/221 [00:04<00:04, 26.46it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 112/221 [00:04<00:04, 26.77it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 115/221 [00:04<00:04, 25.24it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 118/221 [00:04<00:04, 24.64it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 121/221 [00:04<00:03, 25.40it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 124/221 [00:04<00:03, 25.58it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 127/221 [00:04<00:03, 26.11it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 130/221 [00:04<00:03, 27.00it/s]\u001b[A\n",
      "Applying IIR:  61%|    | 134/221 [00:04<00:03, 27.97it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 138/221 [00:05<00:02, 28.64it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 142/221 [00:05<00:02, 29.76it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 146/221 [00:05<00:02, 30.34it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 150/221 [00:05<00:02, 28.68it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 153/221 [00:05<00:02, 26.42it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 156/221 [00:05<00:02, 25.15it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 159/221 [00:05<00:02, 26.37it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 163/221 [00:05<00:02, 27.98it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 167/221 [00:06<00:01, 29.52it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 171/221 [00:06<00:01, 30.68it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 175/221 [00:06<00:01, 31.22it/s]\u001b[A\n",
      "Applying IIR:  81%|  | 179/221 [00:06<00:01, 30.80it/s]\u001b[A\n",
      "Applying IIR:  83%| | 183/221 [00:06<00:01, 31.44it/s]\u001b[A\n",
      "Applying IIR:  85%| | 187/221 [00:06<00:01, 31.40it/s]\u001b[A\n",
      "Applying IIR:  86%| | 191/221 [00:06<00:00, 30.90it/s]\u001b[A\n",
      "Applying IIR:  88%| | 195/221 [00:06<00:00, 31.55it/s]\u001b[A\n",
      "Applying IIR:  90%| | 199/221 [00:07<00:00, 32.03it/s]\u001b[A\n",
      "Applying IIR:  92%|| 203/221 [00:07<00:00, 30.26it/s]\u001b[A\n",
      "Applying IIR:  94%|| 207/221 [00:07<00:00, 29.32it/s]\u001b[A\n",
      "Applying IIR:  95%|| 211/221 [00:07<00:00, 29.58it/s]\u001b[A\n",
      "Applying IIR:  97%|| 215/221 [00:07<00:00, 30.73it/s]\u001b[A\n",
      "Applying IIR: 100%|| 221/221 [00:07<00:00, 28.23it/s]\u001b[A\n",
      " 10%|         | 2/21 [00:23<04:10, 13.20s/it]\n",
      "Applying IIR:   0%|          | 0/223 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/223 [00:00<00:08, 24.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1690464_1916010_B_003.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1690464_1916010_B_003.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/223 [00:00<00:08, 25.29it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 10/223 [00:00<00:08, 26.55it/s]\u001b[A\n",
      "Applying IIR:   6%|         | 13/223 [00:00<00:07, 27.24it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 16/223 [00:00<00:07, 27.69it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 19/223 [00:00<00:07, 26.52it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 23/223 [00:00<00:07, 27.78it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/223 [00:00<00:06, 29.36it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 30/223 [00:01<00:06, 29.33it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/223 [00:01<00:06, 29.46it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/223 [00:01<00:06, 29.58it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/223 [00:01<00:06, 27.12it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/223 [00:01<00:06, 26.65it/s]\u001b[A\n",
      "Applying IIR:  21%|        | 46/223 [00:01<00:06, 27.77it/s]\u001b[A\n",
      "Applying IIR:  22%|       | 50/223 [00:01<00:06, 28.53it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/223 [00:01<00:05, 29.83it/s]\u001b[A\n",
      "Applying IIR:  26%|       | 58/223 [00:01<00:05, 31.22it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 62/223 [00:02<00:04, 32.42it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 66/223 [00:02<00:04, 32.71it/s]\u001b[A\n",
      "Applying IIR:  31%|      | 70/223 [00:02<00:04, 32.45it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 74/223 [00:02<00:04, 32.43it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 78/223 [00:02<00:04, 29.74it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 82/223 [00:02<00:05, 27.88it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 86/223 [00:02<00:04, 28.54it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 89/223 [00:03<00:04, 27.69it/s]\u001b[A\n",
      "Applying IIR:  41%|     | 92/223 [00:03<00:04, 27.11it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 96/223 [00:03<00:04, 28.88it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 99/223 [00:03<00:04, 28.98it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 102/223 [00:03<00:04, 27.07it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 105/223 [00:03<00:04, 26.94it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 108/223 [00:03<00:04, 26.24it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 111/223 [00:03<00:04, 26.27it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 114/223 [00:03<00:04, 27.10it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 117/223 [00:04<00:04, 26.13it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 120/223 [00:04<00:04, 25.69it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 124/223 [00:04<00:03, 27.63it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 127/223 [00:04<00:03, 27.45it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 130/223 [00:04<00:03, 27.11it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 134/223 [00:04<00:03, 28.93it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 138/223 [00:04<00:02, 30.27it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 142/223 [00:04<00:02, 28.69it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 145/223 [00:05<00:02, 28.87it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 148/223 [00:05<00:02, 27.61it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 151/223 [00:05<00:02, 26.94it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 154/223 [00:05<00:02, 27.73it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 157/223 [00:05<00:02, 27.48it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 160/223 [00:05<00:02, 25.92it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 163/223 [00:05<00:02, 25.57it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 167/223 [00:05<00:02, 27.67it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 171/223 [00:06<00:01, 28.21it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 175/223 [00:06<00:01, 28.88it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 179/223 [00:06<00:01, 29.76it/s]\u001b[A\n",
      "Applying IIR:  82%| | 183/223 [00:06<00:01, 30.20it/s]\u001b[A\n",
      "Applying IIR:  84%| | 187/223 [00:06<00:01, 28.34it/s]\u001b[A\n",
      "Applying IIR:  85%| | 190/223 [00:06<00:01, 28.28it/s]\u001b[A\n",
      "Applying IIR:  87%| | 193/223 [00:06<00:01, 27.23it/s]\u001b[A\n",
      "Applying IIR:  88%| | 196/223 [00:06<00:00, 27.65it/s]\u001b[A\n",
      "Applying IIR:  89%| | 199/223 [00:06<00:00, 27.01it/s]\u001b[A\n",
      "Applying IIR:  91%| | 202/223 [00:07<00:00, 26.91it/s]\u001b[A\n",
      "Applying IIR:  92%|| 205/223 [00:07<00:00, 26.07it/s]\u001b[A\n",
      "Applying IIR:  93%|| 208/223 [00:07<00:00, 27.06it/s]\u001b[A\n",
      "Applying IIR:  95%|| 211/223 [00:07<00:00, 27.68it/s]\u001b[A\n",
      "Applying IIR:  96%|| 214/223 [00:07<00:00, 27.16it/s]\u001b[A\n",
      "Applying IIR:  97%|| 217/223 [00:07<00:00, 26.12it/s]\u001b[A\n",
      "Applying IIR:  99%|| 220/223 [00:07<00:00, 26.29it/s]\u001b[A\n",
      "Applying IIR: 100%|| 223/223 [00:07<00:00, 28.23it/s]\u001b[A\n",
      " 14%|        | 3/21 [00:31<03:30, 11.68s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:10, 21.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 2059066_1916010_B_001.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/2059066_1916010_B_001.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:10, 21.32it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:09, 21.71it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:09, 23.15it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:08, 23.61it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:08, 24.03it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:08, 24.12it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 24/225 [00:01<00:08, 23.81it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/225 [00:01<00:08, 23.74it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 30/225 [00:01<00:08, 23.31it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/225 [00:01<00:08, 22.97it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/225 [00:01<00:08, 22.95it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/225 [00:01<00:08, 22.47it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/225 [00:01<00:07, 24.12it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 45/225 [00:01<00:07, 25.34it/s]\u001b[A\n",
      "Applying IIR:  21%|       | 48/225 [00:01<00:06, 26.43it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 52/225 [00:02<00:06, 28.07it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 55/225 [00:02<00:06, 28.15it/s]\u001b[A\n",
      "Applying IIR:  26%|       | 58/225 [00:02<00:05, 28.26it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 61/225 [00:02<00:06, 26.18it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 64/225 [00:02<00:06, 25.37it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 67/225 [00:02<00:06, 25.50it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 70/225 [00:02<00:06, 25.15it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 73/225 [00:02<00:06, 24.55it/s]\u001b[A\n",
      "Applying IIR:  34%|      | 76/225 [00:03<00:06, 24.40it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 79/225 [00:03<00:05, 24.56it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 82/225 [00:03<00:05, 25.39it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 85/225 [00:03<00:05, 26.13it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 88/225 [00:03<00:05, 27.10it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 91/225 [00:03<00:04, 26.87it/s]\u001b[A\n",
      "Applying IIR:  42%|     | 94/225 [00:03<00:05, 26.08it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 97/225 [00:03<00:04, 25.81it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 101/225 [00:03<00:04, 27.62it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 105/225 [00:04<00:04, 28.60it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 109/225 [00:04<00:03, 29.57it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 113/225 [00:04<00:03, 30.79it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 117/225 [00:04<00:03, 31.51it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 121/225 [00:04<00:03, 32.15it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 125/225 [00:04<00:03, 29.33it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 128/225 [00:04<00:03, 28.78it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 131/225 [00:04<00:03, 28.99it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 135/225 [00:05<00:03, 29.94it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 139/225 [00:05<00:02, 30.09it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 143/225 [00:05<00:02, 30.94it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 147/225 [00:05<00:02, 29.08it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 150/225 [00:05<00:02, 28.61it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 153/225 [00:05<00:02, 27.81it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 156/225 [00:05<00:02, 26.29it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 159/225 [00:05<00:02, 26.23it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 162/225 [00:06<00:02, 27.16it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 166/225 [00:06<00:02, 28.95it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 170/225 [00:06<00:01, 29.89it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 174/225 [00:06<00:01, 30.86it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 178/225 [00:06<00:01, 31.59it/s]\u001b[A\n",
      "Applying IIR:  81%|  | 182/225 [00:06<00:01, 32.22it/s]\u001b[A\n",
      "Applying IIR:  83%| | 186/225 [00:06<00:01, 32.54it/s]\u001b[A\n",
      "Applying IIR:  84%| | 190/225 [00:06<00:01, 32.68it/s]\u001b[A\n",
      "Applying IIR:  86%| | 194/225 [00:07<00:01, 30.81it/s]\u001b[A\n",
      "Applying IIR:  88%| | 198/225 [00:07<00:00, 30.83it/s]\u001b[A\n",
      "Applying IIR:  90%| | 202/225 [00:07<00:00, 31.09it/s]\u001b[A\n",
      "Applying IIR:  92%|| 206/225 [00:07<00:00, 31.02it/s]\u001b[A\n",
      "Applying IIR:  93%|| 210/225 [00:07<00:00, 31.60it/s]\u001b[A\n",
      "Applying IIR:  95%|| 214/225 [00:07<00:00, 31.98it/s]\u001b[A\n",
      "Applying IIR:  97%|| 218/225 [00:07<00:00, 32.03it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 27.91it/s]\u001b[A\n",
      " 19%|        | 4/21 [00:39<03:01, 10.66s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:08, 24.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1853436_1916010_B_001.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1853436_1916010_B_001.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:08, 26.05it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:08, 25.84it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:08, 26.61it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:07, 26.91it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:07, 27.16it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:07, 27.83it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 24/225 [00:00<00:07, 28.38it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/225 [00:00<00:06, 28.33it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 30/225 [00:01<00:06, 28.50it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/225 [00:01<00:06, 27.77it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/225 [00:01<00:06, 27.96it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/225 [00:01<00:06, 27.54it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/225 [00:01<00:06, 27.89it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 45/225 [00:01<00:06, 28.19it/s]\u001b[A\n",
      "Applying IIR:  21%|       | 48/225 [00:01<00:06, 25.91it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 51/225 [00:01<00:06, 25.07it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:02<00:06, 25.09it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:02<00:06, 24.49it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 60/225 [00:02<00:06, 24.26it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 63/225 [00:02<00:06, 24.76it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 66/225 [00:02<00:06, 25.99it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 69/225 [00:02<00:05, 26.92it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 72/225 [00:02<00:05, 27.67it/s]\u001b[A\n",
      "Applying IIR:  34%|      | 76/225 [00:02<00:05, 28.38it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 80/225 [00:02<00:05, 28.90it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 83/225 [00:03<00:04, 28.51it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 86/225 [00:03<00:04, 28.72it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 89/225 [00:03<00:05, 26.70it/s]\u001b[A\n",
      "Applying IIR:  41%|      | 92/225 [00:03<00:04, 26.90it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 96/225 [00:03<00:04, 27.83it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 100/225 [00:03<00:04, 28.47it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 103/225 [00:03<00:04, 26.99it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 106/225 [00:03<00:04, 27.54it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 109/225 [00:03<00:04, 28.15it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 112/225 [00:04<00:03, 28.60it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 115/225 [00:04<00:03, 28.60it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 118/225 [00:04<00:03, 27.18it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 121/225 [00:04<00:03, 26.98it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 124/225 [00:04<00:03, 26.27it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 127/225 [00:04<00:03, 26.28it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 130/225 [00:04<00:03, 26.80it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 133/225 [00:04<00:03, 27.42it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 136/225 [00:05<00:03, 26.56it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 139/225 [00:05<00:03, 26.35it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 142/225 [00:05<00:03, 25.57it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 145/225 [00:05<00:03, 25.13it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 148/225 [00:05<00:03, 25.49it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 151/225 [00:05<00:02, 26.08it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 154/225 [00:05<00:02, 26.76it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 157/225 [00:05<00:02, 26.97it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 160/225 [00:05<00:02, 26.81it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 163/225 [00:06<00:02, 26.88it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 166/225 [00:06<00:02, 27.36it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 170/225 [00:06<00:01, 27.89it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 173/225 [00:06<00:01, 26.77it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 176/225 [00:06<00:01, 26.91it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 179/225 [00:06<00:01, 26.56it/s]\u001b[A\n",
      "Applying IIR:  81%|  | 182/225 [00:06<00:01, 26.74it/s]\u001b[A\n",
      "Applying IIR:  82%| | 185/225 [00:06<00:01, 27.05it/s]\u001b[A\n",
      "Applying IIR:  84%| | 189/225 [00:06<00:01, 28.13it/s]\u001b[A\n",
      "Applying IIR:  85%| | 192/225 [00:07<00:01, 26.61it/s]\u001b[A\n",
      "Applying IIR:  87%| | 195/225 [00:07<00:01, 26.47it/s]\u001b[A\n",
      "Applying IIR:  88%| | 198/225 [00:07<00:01, 26.62it/s]\u001b[A\n",
      "Applying IIR:  89%| | 201/225 [00:07<00:00, 25.25it/s]\u001b[A\n",
      "Applying IIR:  91%| | 204/225 [00:07<00:00, 25.11it/s]\u001b[A\n",
      "Applying IIR:  92%|| 207/225 [00:07<00:00, 26.37it/s]\u001b[A\n",
      "Applying IIR:  93%|| 210/225 [00:07<00:00, 25.99it/s]\u001b[A\n",
      "Applying IIR:  95%|| 213/225 [00:07<00:00, 25.58it/s]\u001b[A\n",
      "Applying IIR:  96%|| 216/225 [00:08<00:00, 25.49it/s]\u001b[A\n",
      "Applying IIR:  97%|| 219/225 [00:08<00:00, 25.18it/s]\u001b[A\n",
      "Applying IIR:  99%|| 222/225 [00:08<00:00, 25.23it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 26.76it/s]\u001b[A\n",
      " 24%|       | 5/21 [00:48<02:40, 10.05s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:08, 25.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1690464_1916010_B_002.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1690464_1916010_B_002.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:08, 25.21it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:08, 25.83it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:08, 24.41it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:08, 24.87it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:08, 23.63it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:08, 23.71it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 24/225 [00:00<00:08, 24.30it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/225 [00:01<00:07, 25.55it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 30/225 [00:01<00:07, 26.57it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/225 [00:01<00:07, 27.22it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/225 [00:01<00:06, 27.43it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/225 [00:01<00:06, 27.22it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/225 [00:01<00:06, 27.38it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 45/225 [00:01<00:06, 26.54it/s]\u001b[A\n",
      "Applying IIR:  21%|       | 48/225 [00:01<00:06, 26.59it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 51/225 [00:01<00:06, 27.41it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:02<00:06, 26.80it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:02<00:06, 25.68it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 60/225 [00:02<00:06, 25.79it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 63/225 [00:02<00:06, 25.86it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 66/225 [00:02<00:06, 26.21it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 69/225 [00:02<00:05, 26.69it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 72/225 [00:02<00:05, 27.23it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 75/225 [00:02<00:05, 27.71it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 78/225 [00:02<00:05, 27.99it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 81/225 [00:03<00:05, 28.35it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 84/225 [00:03<00:04, 28.62it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 87/225 [00:03<00:04, 28.65it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 91/225 [00:03<00:04, 29.88it/s]\u001b[A\n",
      "Applying IIR:  42%|     | 95/225 [00:03<00:04, 30.55it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 99/225 [00:03<00:04, 28.03it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 102/225 [00:03<00:04, 25.93it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 105/225 [00:03<00:04, 25.88it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 108/225 [00:04<00:04, 26.88it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 111/225 [00:04<00:04, 27.02it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 115/225 [00:04<00:03, 28.15it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 119/225 [00:04<00:03, 29.40it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 123/225 [00:04<00:03, 29.93it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 127/225 [00:04<00:03, 27.16it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 130/225 [00:04<00:03, 26.54it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 133/225 [00:04<00:03, 25.51it/s]\u001b[A\n",
      "Applying IIR:  61%|    | 137/225 [00:05<00:03, 27.21it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 141/225 [00:05<00:03, 27.50it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 144/225 [00:05<00:03, 25.05it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 147/225 [00:05<00:03, 24.70it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 151/225 [00:05<00:02, 26.15it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 154/225 [00:05<00:02, 27.14it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 157/225 [00:05<00:02, 26.36it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 160/225 [00:05<00:02, 25.07it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 163/225 [00:06<00:02, 25.65it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 166/225 [00:06<00:02, 24.84it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 169/225 [00:06<00:02, 24.52it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 172/225 [00:06<00:02, 25.88it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 175/225 [00:06<00:01, 26.67it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 178/225 [00:06<00:01, 27.21it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 181/225 [00:06<00:01, 27.88it/s]\u001b[A\n",
      "Applying IIR:  82%| | 184/225 [00:06<00:01, 26.35it/s]\u001b[A\n",
      "Applying IIR:  83%| | 187/225 [00:06<00:01, 26.76it/s]\u001b[A\n",
      "Applying IIR:  84%| | 190/225 [00:07<00:01, 27.02it/s]\u001b[A\n",
      "Applying IIR:  86%| | 193/225 [00:07<00:01, 25.81it/s]\u001b[A\n",
      "Applying IIR:  87%| | 196/225 [00:07<00:01, 24.89it/s]\u001b[A\n",
      "Applying IIR:  89%| | 200/225 [00:07<00:00, 26.95it/s]\u001b[A\n",
      "Applying IIR:  91%| | 204/225 [00:07<00:00, 28.77it/s]\u001b[A\n",
      "Applying IIR:  92%|| 208/225 [00:07<00:00, 28.64it/s]\u001b[A\n",
      "Applying IIR:  94%|| 211/225 [00:07<00:00, 28.03it/s]\u001b[A\n",
      "Applying IIR:  95%|| 214/225 [00:07<00:00, 26.46it/s]\u001b[A\n",
      "Applying IIR:  96%|| 217/225 [00:08<00:00, 24.44it/s]\u001b[A\n",
      "Applying IIR:  98%|| 220/225 [00:08<00:00, 24.76it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 26.77it/s]\u001b[A\n",
      " 29%|       | 6/21 [00:57<02:24,  9.63s/it]\n",
      "Applying IIR:   0%|          | 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/221 [00:00<00:10, 21.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1941250_1916010_B_003.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1941250_1916010_B_003.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/221 [00:00<00:09, 23.26it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/221 [00:00<00:08, 24.66it/s]\u001b[A\n",
      "Applying IIR:   6%|         | 13/221 [00:00<00:07, 26.34it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 16/221 [00:00<00:07, 26.78it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 19/221 [00:00<00:07, 27.06it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 23/221 [00:00<00:07, 28.10it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/221 [00:00<00:06, 29.46it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 31/221 [00:01<00:06, 30.26it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 35/221 [00:01<00:06, 29.61it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 38/221 [00:01<00:06, 28.17it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/221 [00:01<00:06, 28.76it/s]\u001b[A\n",
      "Applying IIR:  21%|        | 46/221 [00:01<00:05, 29.30it/s]\u001b[A\n",
      "Applying IIR:  22%|       | 49/221 [00:01<00:06, 26.98it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 52/221 [00:01<00:06, 26.80it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 55/221 [00:01<00:06, 26.13it/s]\u001b[A\n",
      "Applying IIR:  26%|       | 58/221 [00:02<00:06, 25.10it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 61/221 [00:02<00:06, 25.08it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 64/221 [00:02<00:06, 24.97it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 67/221 [00:02<00:06, 25.49it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 70/221 [00:02<00:06, 24.59it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 73/221 [00:02<00:05, 24.85it/s]\u001b[A\n",
      "Applying IIR:  34%|      | 76/221 [00:02<00:05, 25.31it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 79/221 [00:02<00:05, 24.39it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 82/221 [00:03<00:05, 23.77it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 85/221 [00:03<00:05, 24.83it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 88/221 [00:03<00:05, 24.79it/s]\u001b[A\n",
      "Applying IIR:  41%|      | 91/221 [00:03<00:05, 24.70it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 94/221 [00:03<00:04, 25.90it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 97/221 [00:03<00:04, 26.75it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 100/221 [00:03<00:04, 25.63it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 103/221 [00:03<00:04, 25.11it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 106/221 [00:03<00:04, 26.17it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 109/221 [00:04<00:04, 26.95it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 112/221 [00:04<00:04, 26.98it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 115/221 [00:04<00:04, 25.83it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 118/221 [00:04<00:03, 26.37it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 121/221 [00:04<00:04, 24.54it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 124/221 [00:04<00:03, 24.69it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 127/221 [00:04<00:03, 24.52it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 130/221 [00:04<00:03, 24.13it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 133/221 [00:05<00:03, 25.08it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 136/221 [00:05<00:03, 24.10it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 139/221 [00:05<00:03, 23.33it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 142/221 [00:05<00:03, 24.69it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 146/221 [00:05<00:02, 26.63it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 150/221 [00:05<00:02, 28.16it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 153/221 [00:05<00:02, 26.88it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 156/221 [00:05<00:02, 26.85it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 159/221 [00:06<00:02, 27.23it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 163/221 [00:06<00:02, 28.25it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 167/221 [00:06<00:01, 29.49it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 171/221 [00:06<00:01, 30.29it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 175/221 [00:06<00:01, 30.39it/s]\u001b[A\n",
      "Applying IIR:  81%|  | 179/221 [00:06<00:01, 29.76it/s]\u001b[A\n",
      "Applying IIR:  82%| | 182/221 [00:06<00:01, 29.43it/s]\u001b[A\n",
      "Applying IIR:  84%| | 185/221 [00:06<00:01, 27.03it/s]\u001b[A\n",
      "Applying IIR:  86%| | 189/221 [00:07<00:01, 28.23it/s]\u001b[A\n",
      "Applying IIR:  87%| | 192/221 [00:07<00:01, 27.77it/s]\u001b[A\n",
      "Applying IIR:  88%| | 195/221 [00:07<00:00, 28.27it/s]\u001b[A\n",
      "Applying IIR:  90%| | 199/221 [00:07<00:00, 28.87it/s]\u001b[A\n",
      "Applying IIR:  91%|| 202/221 [00:07<00:00, 27.31it/s]\u001b[A\n",
      "Applying IIR:  93%|| 206/221 [00:07<00:00, 28.41it/s]\u001b[A\n",
      "Applying IIR:  95%|| 210/221 [00:07<00:00, 29.32it/s]\u001b[A\n",
      "Applying IIR:  96%|| 213/221 [00:07<00:00, 27.56it/s]\u001b[A\n",
      "Applying IIR:  98%|| 216/221 [00:07<00:00, 27.40it/s]\u001b[A\n",
      "Applying IIR: 100%|| 221/221 [00:08<00:00, 27.08it/s]\u001b[A\n",
      " 33%|      | 7/21 [01:05<02:09,  9.26s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:08, 26.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1255229_1916010_B_002.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1255229_1916010_B_002.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   2%|         | 5/225 [00:00<00:09, 23.99it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 8/225 [00:00<00:08, 24.37it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 11/225 [00:00<00:08, 25.11it/s]\u001b[A\n",
      "Applying IIR:   6%|         | 14/225 [00:00<00:08, 25.93it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 17/225 [00:00<00:08, 25.63it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:07, 27.47it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 24/225 [00:00<00:07, 27.34it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/225 [00:01<00:07, 27.30it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 30/225 [00:01<00:07, 25.64it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/225 [00:01<00:07, 26.63it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/225 [00:01<00:07, 26.24it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/225 [00:01<00:06, 27.20it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 43/225 [00:01<00:06, 27.88it/s]\u001b[A\n",
      "Applying IIR:  21%|        | 47/225 [00:01<00:06, 29.01it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 51/225 [00:01<00:05, 30.07it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 55/225 [00:01<00:05, 30.73it/s]\u001b[A\n",
      "Applying IIR:  26%|       | 59/225 [00:02<00:05, 28.30it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 62/225 [00:02<00:05, 27.42it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 65/225 [00:02<00:05, 27.36it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 68/225 [00:02<00:05, 27.97it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 71/225 [00:02<00:05, 26.35it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 74/225 [00:02<00:05, 25.96it/s]\u001b[A\n",
      "Applying IIR:  34%|      | 77/225 [00:02<00:05, 25.70it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 80/225 [00:02<00:05, 26.15it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 83/225 [00:03<00:05, 26.59it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 86/225 [00:03<00:05, 26.89it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 89/225 [00:03<00:05, 27.17it/s]\u001b[A\n",
      "Applying IIR:  41%|      | 92/225 [00:03<00:05, 25.15it/s]\u001b[A\n",
      "Applying IIR:  42%|     | 95/225 [00:03<00:05, 25.25it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 98/225 [00:03<00:04, 25.50it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 101/225 [00:03<00:04, 25.81it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 104/225 [00:03<00:04, 26.46it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 107/225 [00:03<00:04, 27.01it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 110/225 [00:04<00:04, 26.62it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 113/225 [00:04<00:04, 26.02it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 116/225 [00:04<00:04, 24.46it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 119/225 [00:04<00:04, 25.64it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 122/225 [00:04<00:03, 26.15it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 125/225 [00:04<00:03, 26.54it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 128/225 [00:04<00:03, 26.67it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 131/225 [00:04<00:03, 26.18it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 134/225 [00:05<00:03, 24.94it/s]\u001b[A\n",
      "Applying IIR:  61%|    | 137/225 [00:05<00:03, 24.21it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 140/225 [00:05<00:03, 23.75it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 143/225 [00:05<00:03, 24.17it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 146/225 [00:05<00:03, 23.69it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 149/225 [00:05<00:03, 23.86it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 152/225 [00:05<00:02, 24.81it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 155/225 [00:05<00:02, 23.70it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 158/225 [00:06<00:02, 24.20it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 161/225 [00:06<00:02, 23.46it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 164/225 [00:06<00:02, 22.85it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 167/225 [00:06<00:02, 23.55it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 170/225 [00:06<00:02, 24.37it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 174/225 [00:06<00:01, 25.79it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 177/225 [00:06<00:01, 26.74it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 180/225 [00:06<00:01, 27.53it/s]\u001b[A\n",
      "Applying IIR:  81%| | 183/225 [00:06<00:01, 27.94it/s]\u001b[A\n",
      "Applying IIR:  83%| | 186/225 [00:07<00:01, 28.42it/s]\u001b[A\n",
      "Applying IIR:  84%| | 189/225 [00:07<00:01, 27.14it/s]\u001b[A\n",
      "Applying IIR:  85%| | 192/225 [00:07<00:01, 25.28it/s]\u001b[A\n",
      "Applying IIR:  87%| | 195/225 [00:07<00:01, 26.10it/s]\u001b[A\n",
      "Applying IIR:  88%| | 198/225 [00:07<00:01, 25.33it/s]\u001b[A\n",
      "Applying IIR:  89%| | 201/225 [00:07<00:00, 25.51it/s]\u001b[A\n",
      "Applying IIR:  91%| | 204/225 [00:07<00:00, 25.80it/s]\u001b[A\n",
      "Applying IIR:  92%|| 207/225 [00:07<00:00, 26.75it/s]\u001b[A\n",
      "Applying IIR:  93%|| 210/225 [00:08<00:00, 27.29it/s]\u001b[A\n",
      "Applying IIR:  95%|| 213/225 [00:08<00:00, 27.65it/s]\u001b[A\n",
      "Applying IIR:  96%|| 216/225 [00:08<00:00, 27.49it/s]\u001b[A\n",
      "Applying IIR:  97%|| 219/225 [00:08<00:00, 25.28it/s]\u001b[A\n",
      "Applying IIR:  99%|| 222/225 [00:08<00:00, 24.75it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 26.06it/s]\u001b[A\n",
      " 38%|      | 8/21 [01:14<01:58,  9.14s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:08, 24.96it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1260311_1916010_B_001.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1260311_1916010_B_001.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:08, 25.31it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:08, 25.82it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:07, 26.78it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:08, 25.57it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:08, 25.76it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:07, 26.74it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 25/225 [00:00<00:07, 28.13it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 28/225 [00:01<00:07, 27.58it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 31/225 [00:01<00:06, 28.03it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 34/225 [00:01<00:07, 26.43it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 37/225 [00:01<00:07, 26.42it/s]\u001b[A\n",
      "Applying IIR:  18%|        | 40/225 [00:01<00:07, 25.51it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 43/225 [00:01<00:07, 24.74it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 46/225 [00:01<00:07, 24.86it/s]\u001b[A\n",
      "Applying IIR:  22%|       | 49/225 [00:01<00:06, 25.30it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 52/225 [00:01<00:07, 24.58it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 55/225 [00:02<00:07, 23.24it/s]\u001b[A\n",
      "Applying IIR:  26%|       | 58/225 [00:02<00:07, 22.90it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 61/225 [00:02<00:06, 23.79it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 64/225 [00:02<00:06, 25.10it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 67/225 [00:02<00:06, 26.28it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 70/225 [00:02<00:06, 25.35it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 73/225 [00:02<00:05, 26.11it/s]\u001b[A\n",
      "Applying IIR:  34%|      | 76/225 [00:02<00:05, 26.79it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 79/225 [00:03<00:05, 27.44it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 82/225 [00:03<00:05, 27.69it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 85/225 [00:03<00:05, 27.63it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 88/225 [00:03<00:05, 27.30it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 91/225 [00:03<00:04, 27.08it/s]\u001b[A\n",
      "Applying IIR:  42%|     | 94/225 [00:03<00:05, 25.18it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 97/225 [00:03<00:05, 25.14it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 100/225 [00:03<00:04, 25.25it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 103/225 [00:03<00:04, 26.17it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 106/225 [00:04<00:04, 26.80it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 109/225 [00:04<00:04, 27.62it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 112/225 [00:04<00:04, 27.83it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 115/225 [00:04<00:03, 28.38it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 118/225 [00:04<00:03, 28.34it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 121/225 [00:04<00:03, 27.01it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 124/225 [00:04<00:03, 27.22it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 127/225 [00:04<00:03, 27.27it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 130/225 [00:04<00:03, 26.97it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 134/225 [00:05<00:03, 28.07it/s]\u001b[A\n",
      "Applying IIR:  61%|    | 137/225 [00:05<00:03, 28.39it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 140/225 [00:05<00:03, 28.21it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 143/225 [00:05<00:02, 28.13it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 146/225 [00:05<00:02, 28.01it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 150/225 [00:05<00:02, 29.13it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 153/225 [00:05<00:02, 28.88it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 156/225 [00:05<00:02, 28.38it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 159/225 [00:05<00:02, 28.45it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 162/225 [00:06<00:02, 27.59it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 166/225 [00:06<00:02, 28.97it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 170/225 [00:06<00:01, 29.55it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 173/225 [00:06<00:01, 29.63it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 177/225 [00:06<00:01, 30.13it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 181/225 [00:06<00:01, 31.15it/s]\u001b[A\n",
      "Applying IIR:  82%| | 185/225 [00:06<00:01, 31.47it/s]\u001b[A\n",
      "Applying IIR:  84%| | 189/225 [00:06<00:01, 31.20it/s]\u001b[A\n",
      "Applying IIR:  86%| | 193/225 [00:07<00:01, 31.04it/s]\u001b[A\n",
      "Applying IIR:  88%| | 197/225 [00:07<00:00, 30.25it/s]\u001b[A\n",
      "Applying IIR:  89%| | 201/225 [00:07<00:00, 27.25it/s]\u001b[A\n",
      "Applying IIR:  91%| | 204/225 [00:07<00:00, 26.45it/s]\u001b[A\n",
      "Applying IIR:  92%|| 207/225 [00:07<00:00, 25.94it/s]\u001b[A\n",
      "Applying IIR:  93%|| 210/225 [00:07<00:00, 26.88it/s]\u001b[A\n",
      "Applying IIR:  95%|| 213/225 [00:07<00:00, 27.60it/s]\u001b[A\n",
      "Applying IIR:  96%|| 216/225 [00:07<00:00, 25.62it/s]\u001b[A\n",
      "Applying IIR:  97%|| 219/225 [00:08<00:00, 25.47it/s]\u001b[A\n",
      "Applying IIR:  99%|| 222/225 [00:08<00:00, 25.87it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 27.18it/s]\u001b[A\n",
      " 43%|     | 9/21 [01:22<01:47,  8.95s/it]\n",
      "Applying IIR:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 3/22 [00:00<00:00, 22.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1941250_1916010_C_002.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1941250_1916010_C_002.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:  27%|       | 6/22 [00:00<00:00, 22.87it/s]\u001b[A\n",
      "Applying IIR:  41%|      | 9/22 [00:00<00:00, 23.22it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 12/22 [00:00<00:00, 24.21it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 15/22 [00:00<00:00, 24.72it/s]\u001b[A\n",
      "Applying IIR:  82%| | 18/22 [00:00<00:00, 25.68it/s]\u001b[A\n",
      "Applying IIR: 100%|| 22/22 [00:00<00:00, 24.37it/s]\u001b[A\n",
      " 48%|     | 10/21 [01:24<01:12,  6.61s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:09, 22.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1690464_1916010_C_003.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1690464_1916010_C_003.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:09, 23.63it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 8/225 [00:00<00:09, 22.39it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 11/225 [00:00<00:09, 22.73it/s]\u001b[A\n",
      "Applying IIR:   6%|         | 14/225 [00:00<00:08, 24.11it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 17/225 [00:00<00:08, 25.48it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 20/225 [00:00<00:07, 25.87it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 23/225 [00:00<00:07, 26.71it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/225 [00:01<00:06, 28.35it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 30/225 [00:01<00:06, 28.09it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/225 [00:01<00:07, 26.82it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/225 [00:01<00:06, 27.07it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/225 [00:01<00:06, 27.88it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 43/225 [00:01<00:06, 27.98it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 46/225 [00:01<00:06, 27.65it/s]\u001b[A\n",
      "Applying IIR:  22%|       | 50/225 [00:01<00:06, 28.68it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:01<00:05, 28.99it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:02<00:06, 27.40it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 60/225 [00:02<00:06, 26.48it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 63/225 [00:02<00:06, 25.60it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 66/225 [00:02<00:06, 25.93it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 69/225 [00:02<00:05, 26.59it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 72/225 [00:02<00:05, 27.22it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 75/225 [00:02<00:05, 27.86it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 78/225 [00:02<00:05, 28.01it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 81/225 [00:02<00:05, 28.50it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 84/225 [00:03<00:04, 28.53it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 87/225 [00:03<00:04, 28.41it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 90/225 [00:03<00:04, 27.13it/s]\u001b[A\n",
      "Applying IIR:  41%|     | 93/225 [00:03<00:04, 27.07it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 96/225 [00:03<00:05, 25.33it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 99/225 [00:03<00:05, 24.19it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 102/225 [00:03<00:04, 24.87it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 105/225 [00:03<00:04, 24.24it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 108/225 [00:04<00:04, 23.82it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 111/225 [00:04<00:04, 23.90it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 114/225 [00:04<00:04, 24.99it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 117/225 [00:04<00:04, 25.88it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 121/225 [00:04<00:03, 27.35it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 124/225 [00:04<00:03, 27.79it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 127/225 [00:04<00:03, 27.84it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 130/225 [00:04<00:03, 28.20it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 133/225 [00:04<00:03, 27.80it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 136/225 [00:05<00:03, 27.01it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 139/225 [00:05<00:03, 27.12it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 142/225 [00:05<00:02, 27.77it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 146/225 [00:05<00:02, 29.15it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 150/225 [00:05<00:02, 30.21it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 154/225 [00:05<00:02, 30.11it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 158/225 [00:05<00:02, 28.86it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 161/225 [00:05<00:02, 27.71it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 164/225 [00:06<00:02, 25.59it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 168/225 [00:06<00:02, 27.59it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 172/225 [00:06<00:01, 29.07it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 175/225 [00:06<00:01, 28.90it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 178/225 [00:06<00:01, 26.76it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 181/225 [00:06<00:01, 26.23it/s]\u001b[A\n",
      "Applying IIR:  82%| | 184/225 [00:06<00:01, 27.09it/s]\u001b[A\n",
      "Applying IIR:  83%| | 187/225 [00:06<00:01, 27.81it/s]\u001b[A\n",
      "Applying IIR:  84%| | 190/225 [00:06<00:01, 28.09it/s]\u001b[A\n",
      "Applying IIR:  86%| | 193/225 [00:07<00:01, 28.17it/s]\u001b[A\n",
      "Applying IIR:  87%| | 196/225 [00:07<00:01, 28.27it/s]\u001b[A\n",
      "Applying IIR:  88%| | 199/225 [00:07<00:00, 28.15it/s]\u001b[A\n",
      "Applying IIR:  90%| | 202/225 [00:07<00:00, 27.66it/s]\u001b[A\n",
      "Applying IIR:  91%| | 205/225 [00:07<00:00, 27.67it/s]\u001b[A\n",
      "Applying IIR:  93%|| 209/225 [00:07<00:00, 28.40it/s]\u001b[A\n",
      "Applying IIR:  94%|| 212/225 [00:07<00:00, 26.92it/s]\u001b[A\n",
      "Applying IIR:  96%|| 215/225 [00:07<00:00, 26.13it/s]\u001b[A\n",
      "Applying IIR:  97%|| 218/225 [00:08<00:00, 24.67it/s]\u001b[A\n",
      "Applying IIR:  98%|| 221/225 [00:08<00:00, 25.59it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 27.11it/s]\u001b[A\n",
      " 52%|    | 11/21 [01:32<01:11,  7.19s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:09, 23.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 2059066_1916010_C_001.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/2059066_1916010_C_001.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:09, 23.34it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:08, 24.04it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:08, 24.05it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:08, 23.36it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:08, 23.69it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:08, 24.10it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 24/225 [00:00<00:08, 24.47it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/225 [00:01<00:07, 25.70it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 30/225 [00:01<00:07, 26.62it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/225 [00:01<00:07, 27.21it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/225 [00:01<00:07, 25.12it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/225 [00:01<00:07, 24.19it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/225 [00:01<00:07, 24.31it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 45/225 [00:01<00:07, 23.68it/s]\u001b[A\n",
      "Applying IIR:  21%|       | 48/225 [00:01<00:07, 24.00it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 51/225 [00:02<00:07, 24.43it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:02<00:06, 25.01it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:02<00:06, 25.18it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 60/225 [00:02<00:06, 25.51it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 63/225 [00:02<00:06, 25.65it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 66/225 [00:02<00:06, 24.92it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 69/225 [00:02<00:06, 25.45it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 72/225 [00:02<00:06, 25.25it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 75/225 [00:03<00:06, 23.54it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 78/225 [00:03<00:06, 24.19it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 81/225 [00:03<00:05, 25.36it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 84/225 [00:03<00:05, 26.52it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 87/225 [00:03<00:05, 26.87it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 90/225 [00:03<00:05, 26.22it/s]\u001b[A\n",
      "Applying IIR:  41%|     | 93/225 [00:03<00:04, 26.75it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 96/225 [00:03<00:04, 26.76it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 99/225 [00:03<00:04, 26.59it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 102/225 [00:04<00:04, 26.47it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 105/225 [00:04<00:04, 26.61it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 108/225 [00:04<00:04, 25.24it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 111/225 [00:04<00:04, 25.43it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 114/225 [00:04<00:04, 23.57it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 117/225 [00:04<00:04, 23.77it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 120/225 [00:04<00:04, 24.96it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 123/225 [00:04<00:04, 25.20it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 126/225 [00:05<00:04, 24.41it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 129/225 [00:05<00:04, 23.70it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 132/225 [00:05<00:03, 23.99it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 135/225 [00:05<00:03, 24.80it/s]\u001b[A\n",
      "Applying IIR:  61%|   | 138/225 [00:05<00:03, 23.99it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 141/225 [00:05<00:03, 23.61it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 144/225 [00:05<00:03, 24.19it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 147/225 [00:05<00:03, 25.37it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 150/225 [00:06<00:02, 25.75it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 153/225 [00:06<00:02, 26.20it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 156/225 [00:06<00:02, 25.01it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 159/225 [00:06<00:02, 24.90it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 162/225 [00:06<00:02, 26.02it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 165/225 [00:06<00:02, 24.80it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 168/225 [00:06<00:02, 24.59it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 171/225 [00:06<00:02, 23.56it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 174/225 [00:06<00:02, 23.71it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 177/225 [00:07<00:01, 24.53it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 180/225 [00:07<00:01, 24.34it/s]\u001b[A\n",
      "Applying IIR:  81%| | 183/225 [00:07<00:01, 23.30it/s]\u001b[A\n",
      "Applying IIR:  83%| | 186/225 [00:07<00:01, 23.94it/s]\u001b[A\n",
      "Applying IIR:  84%| | 189/225 [00:07<00:01, 22.86it/s]\u001b[A\n",
      "Applying IIR:  85%| | 192/225 [00:07<00:01, 22.28it/s]\u001b[A\n",
      "Applying IIR:  87%| | 195/225 [00:07<00:01, 21.74it/s]\u001b[A\n",
      "Applying IIR:  88%| | 198/225 [00:08<00:01, 21.86it/s]\u001b[A\n",
      "Applying IIR:  89%| | 201/225 [00:08<00:01, 22.36it/s]\u001b[A\n",
      "Applying IIR:  91%| | 204/225 [00:08<00:00, 23.61it/s]\u001b[A\n",
      "Applying IIR:  92%|| 207/225 [00:08<00:00, 24.37it/s]\u001b[A\n",
      "Applying IIR:  93%|| 210/225 [00:08<00:00, 24.61it/s]\u001b[A\n",
      "Applying IIR:  95%|| 213/225 [00:08<00:00, 25.69it/s]\u001b[A\n",
      "Applying IIR:  96%|| 216/225 [00:08<00:00, 26.25it/s]\u001b[A\n",
      "Applying IIR:  97%|| 219/225 [00:08<00:00, 26.30it/s]\u001b[A\n",
      "Applying IIR:  99%|| 222/225 [00:09<00:00, 24.29it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:09<00:00, 24.65it/s]\u001b[A\n",
      " 57%|    | 12/21 [01:41<01:10,  7.84s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:09, 22.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1853436_1916010_B_002.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1853436_1916010_B_002.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:09, 23.33it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:08, 24.36it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:08, 25.28it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:08, 25.52it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:07, 26.36it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:07, 26.77it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 24/225 [00:00<00:07, 27.40it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/225 [00:01<00:07, 28.02it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 30/225 [00:01<00:06, 28.11it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/225 [00:01<00:06, 28.44it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/225 [00:01<00:06, 28.55it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/225 [00:01<00:07, 26.44it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/225 [00:01<00:06, 26.16it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 45/225 [00:01<00:06, 26.66it/s]\u001b[A\n",
      "Applying IIR:  21%|       | 48/225 [00:01<00:07, 25.01it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 51/225 [00:01<00:07, 23.91it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:02<00:07, 24.26it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:02<00:07, 23.69it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 60/225 [00:02<00:06, 25.05it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 63/225 [00:02<00:06, 25.69it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 66/225 [00:02<00:06, 25.28it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 69/225 [00:02<00:06, 25.90it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 72/225 [00:02<00:05, 26.50it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 75/225 [00:02<00:05, 27.11it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 78/225 [00:02<00:05, 25.69it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 81/225 [00:03<00:05, 25.65it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 84/225 [00:03<00:05, 25.35it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 87/225 [00:03<00:05, 24.99it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 91/225 [00:03<00:05, 26.68it/s]\u001b[A\n",
      "Applying IIR:  42%|     | 95/225 [00:03<00:04, 28.16it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 98/225 [00:03<00:04, 27.19it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 101/225 [00:03<00:04, 25.31it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 104/225 [00:03<00:04, 25.66it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 107/225 [00:04<00:04, 25.33it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 110/225 [00:04<00:04, 24.64it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 113/225 [00:04<00:04, 24.26it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 116/225 [00:04<00:04, 24.64it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 119/225 [00:04<00:04, 25.57it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 122/225 [00:04<00:03, 26.20it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 125/225 [00:04<00:03, 26.15it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 128/225 [00:04<00:03, 25.86it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 131/225 [00:05<00:03, 25.94it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 134/225 [00:05<00:03, 23.81it/s]\u001b[A\n",
      "Applying IIR:  61%|    | 137/225 [00:05<00:03, 23.79it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 140/225 [00:05<00:03, 23.86it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 143/225 [00:05<00:03, 23.71it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 146/225 [00:05<00:03, 24.08it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 149/225 [00:05<00:03, 25.07it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 152/225 [00:05<00:02, 24.84it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 155/225 [00:06<00:02, 26.14it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 159/225 [00:06<00:02, 27.59it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 163/225 [00:06<00:02, 29.27it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 166/225 [00:06<00:02, 28.25it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 169/225 [00:06<00:01, 28.24it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 172/225 [00:06<00:01, 27.27it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 175/225 [00:06<00:01, 27.46it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 179/225 [00:06<00:01, 28.58it/s]\u001b[A\n",
      "Applying IIR:  81%| | 183/225 [00:06<00:01, 29.80it/s]\u001b[A\n",
      "Applying IIR:  83%| | 187/225 [00:07<00:01, 30.56it/s]\u001b[A\n",
      "Applying IIR:  85%| | 191/225 [00:07<00:01, 30.57it/s]\u001b[A\n",
      "Applying IIR:  87%| | 195/225 [00:07<00:00, 30.47it/s]\u001b[A\n",
      "Applying IIR:  88%| | 199/225 [00:07<00:00, 30.89it/s]\u001b[A\n",
      "Applying IIR:  90%| | 203/225 [00:07<00:00, 28.77it/s]\u001b[A\n",
      "Applying IIR:  92%|| 206/225 [00:07<00:00, 28.01it/s]\u001b[A\n",
      "Applying IIR:  93%|| 210/225 [00:07<00:00, 29.35it/s]\u001b[A\n",
      "Applying IIR:  95%|| 214/225 [00:07<00:00, 30.06it/s]\u001b[A\n",
      "Applying IIR:  97%|| 218/225 [00:08<00:00, 30.50it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 26.92it/s]\u001b[A\n",
      " 62%|   | 13/21 [01:50<01:04,  8.07s/it]\n",
      "Applying IIR:   0%|          | 0/222 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/222 [00:00<00:08, 25.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 2059066_1916010_B_003.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/2059066_1916010_B_003.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/222 [00:00<00:08, 24.95it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/222 [00:00<00:08, 24.80it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/222 [00:00<00:08, 23.63it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/222 [00:00<00:08, 24.23it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/222 [00:00<00:08, 24.83it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 22/222 [00:00<00:07, 26.43it/s]\u001b[A\n",
      "Applying IIR:  11%|        | 25/222 [00:00<00:07, 25.69it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 28/222 [00:01<00:07, 25.15it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 31/222 [00:01<00:07, 24.55it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 34/222 [00:01<00:07, 25.69it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 37/222 [00:01<00:07, 26.36it/s]\u001b[A\n",
      "Applying IIR:  18%|        | 40/222 [00:01<00:07, 25.29it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 43/222 [00:01<00:06, 25.69it/s]\u001b[A\n",
      "Applying IIR:  21%|        | 46/222 [00:01<00:06, 26.53it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 50/222 [00:01<00:06, 28.34it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/222 [00:02<00:05, 29.87it/s]\u001b[A\n",
      "Applying IIR:  26%|       | 58/222 [00:02<00:05, 31.22it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 62/222 [00:02<00:05, 31.70it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 66/222 [00:02<00:04, 32.56it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 70/222 [00:02<00:04, 32.15it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 74/222 [00:02<00:04, 32.04it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 78/222 [00:02<00:04, 31.88it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 82/222 [00:02<00:04, 32.16it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 86/222 [00:03<00:04, 31.29it/s]\u001b[A\n",
      "Applying IIR:  41%|      | 90/222 [00:03<00:04, 27.90it/s]\u001b[A\n",
      "Applying IIR:  42%|     | 93/222 [00:03<00:04, 26.55it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 96/222 [00:03<00:04, 27.23it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 99/222 [00:03<00:04, 26.67it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 102/222 [00:03<00:04, 27.02it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 105/222 [00:03<00:04, 27.54it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 108/222 [00:03<00:04, 26.80it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 111/222 [00:04<00:04, 26.19it/s]\u001b[A\n",
      "Applying IIR:  51%|    | 114/222 [00:04<00:04, 26.70it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 117/222 [00:04<00:03, 26.92it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 120/222 [00:04<00:03, 26.15it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 123/222 [00:04<00:03, 24.82it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 126/222 [00:04<00:03, 26.12it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 130/222 [00:04<00:03, 27.17it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 133/222 [00:04<00:03, 27.62it/s]\u001b[A\n",
      "Applying IIR:  61%|   | 136/222 [00:04<00:03, 28.07it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 140/222 [00:05<00:02, 28.67it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 144/222 [00:05<00:02, 29.05it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 147/222 [00:05<00:02, 28.03it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 150/222 [00:05<00:02, 26.50it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 153/222 [00:05<00:02, 24.96it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 156/222 [00:05<00:02, 24.56it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 159/222 [00:05<00:02, 24.40it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 162/222 [00:05<00:02, 24.03it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 165/222 [00:06<00:02, 24.21it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 168/222 [00:06<00:02, 24.09it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 171/222 [00:06<00:02, 23.56it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 174/222 [00:06<00:01, 24.60it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 177/222 [00:06<00:01, 25.90it/s]\u001b[A\n",
      "Applying IIR:  81%|  | 180/222 [00:06<00:01, 25.82it/s]\u001b[A\n",
      "Applying IIR:  82%| | 183/222 [00:06<00:01, 25.08it/s]\u001b[A\n",
      "Applying IIR:  84%| | 186/222 [00:06<00:01, 24.59it/s]\u001b[A\n",
      "Applying IIR:  85%| | 189/222 [00:07<00:01, 24.77it/s]\u001b[A\n",
      "Applying IIR:  86%| | 192/222 [00:07<00:01, 25.60it/s]\u001b[A\n",
      "Applying IIR:  88%| | 195/222 [00:07<00:01, 25.72it/s]\u001b[A\n",
      "Applying IIR:  89%| | 198/222 [00:07<00:01, 23.92it/s]\u001b[A\n",
      "Applying IIR:  91%| | 201/222 [00:07<00:00, 23.18it/s]\u001b[A\n",
      "Applying IIR:  92%|| 204/222 [00:07<00:00, 24.41it/s]\u001b[A\n",
      "Applying IIR:  93%|| 207/222 [00:07<00:00, 24.55it/s]\u001b[A\n",
      "Applying IIR:  95%|| 210/222 [00:07<00:00, 25.38it/s]\u001b[A\n",
      "Applying IIR:  96%|| 213/222 [00:07<00:00, 25.81it/s]\u001b[A\n",
      "Applying IIR:  97%|| 216/222 [00:08<00:00, 25.70it/s]\u001b[A\n",
      "Applying IIR:  99%|| 219/222 [00:08<00:00, 26.31it/s]\u001b[A\n",
      "Applying IIR: 100%|| 222/222 [00:08<00:00, 26.62it/s]\u001b[A\n",
      " 67%|   | 14/21 [01:59<00:57,  8.22s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:08, 25.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1690464_1916010_B_001.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1690464_1916010_B_001.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:09, 24.26it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:08, 24.95it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:08, 25.63it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:08, 25.14it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:08, 24.69it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:07, 25.61it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 25/225 [00:00<00:07, 26.25it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 28/225 [00:01<00:07, 25.88it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 31/225 [00:01<00:07, 25.61it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 34/225 [00:01<00:07, 26.66it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 38/225 [00:01<00:06, 28.12it/s]\u001b[A\n",
      "Applying IIR:  18%|        | 41/225 [00:01<00:06, 27.53it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 45/225 [00:01<00:06, 27.95it/s]\u001b[A\n",
      "Applying IIR:  21%|       | 48/225 [00:01<00:06, 27.46it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 51/225 [00:01<00:06, 27.60it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:02<00:06, 27.96it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:02<00:06, 26.82it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 60/225 [00:02<00:06, 26.15it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 63/225 [00:02<00:06, 25.44it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 66/225 [00:02<00:06, 25.12it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 69/225 [00:02<00:06, 24.27it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 72/225 [00:02<00:06, 23.85it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 75/225 [00:02<00:06, 23.27it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 78/225 [00:03<00:06, 23.67it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 81/225 [00:03<00:05, 24.10it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 84/225 [00:03<00:06, 23.40it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 87/225 [00:03<00:05, 23.32it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 90/225 [00:03<00:05, 22.98it/s]\u001b[A\n",
      "Applying IIR:  41%|     | 93/225 [00:03<00:05, 23.12it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 96/225 [00:03<00:05, 22.98it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 99/225 [00:03<00:05, 23.67it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 102/225 [00:04<00:05, 24.36it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 106/225 [00:04<00:04, 25.93it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 110/225 [00:04<00:04, 26.50it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 113/225 [00:04<00:04, 25.77it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 116/225 [00:04<00:04, 25.87it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 119/225 [00:04<00:04, 25.35it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 122/225 [00:04<00:04, 23.99it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 125/225 [00:04<00:04, 22.90it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 128/225 [00:05<00:04, 22.88it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 131/225 [00:05<00:04, 22.82it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 135/225 [00:05<00:03, 24.68it/s]\u001b[A\n",
      "Applying IIR:  61%|   | 138/225 [00:05<00:03, 25.61it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 141/225 [00:05<00:03, 24.44it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 144/225 [00:05<00:03, 25.38it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 148/225 [00:05<00:02, 27.02it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 152/225 [00:05<00:02, 28.70it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 156/225 [00:06<00:02, 30.03it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 160/225 [00:06<00:02, 28.97it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 163/225 [00:06<00:02, 28.38it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 166/225 [00:06<00:02, 28.03it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 170/225 [00:06<00:01, 29.38it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 174/225 [00:06<00:01, 30.54it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 178/225 [00:06<00:01, 28.72it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 181/225 [00:06<00:01, 27.36it/s]\u001b[A\n",
      "Applying IIR:  82%| | 184/225 [00:07<00:01, 26.40it/s]\u001b[A\n",
      "Applying IIR:  83%| | 187/225 [00:07<00:01, 26.33it/s]\u001b[A\n",
      "Applying IIR:  85%| | 191/225 [00:07<00:01, 28.11it/s]\u001b[A\n",
      "Applying IIR:  86%| | 194/225 [00:07<00:01, 27.36it/s]\u001b[A\n",
      "Applying IIR:  88%| | 198/225 [00:07<00:00, 28.05it/s]\u001b[A\n",
      "Applying IIR:  89%| | 201/225 [00:07<00:00, 28.00it/s]\u001b[A\n",
      "Applying IIR:  91%| | 205/225 [00:07<00:00, 28.44it/s]\u001b[A\n",
      "Applying IIR:  92%|| 208/225 [00:07<00:00, 28.33it/s]\u001b[A\n",
      "Applying IIR:  94%|| 212/225 [00:08<00:00, 29.48it/s]\u001b[A\n",
      "Applying IIR:  96%|| 216/225 [00:08<00:00, 30.25it/s]\u001b[A\n",
      "Applying IIR:  98%|| 220/225 [00:08<00:00, 29.25it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 26.56it/s]\u001b[A\n",
      " 71%|  | 15/21 [02:07<00:50,  8.36s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   2%|         | 4/225 [00:00<00:06, 31.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1255229_1916010_B_001.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1255229_1916010_B_001.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 7/225 [00:00<00:07, 29.38it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 10/225 [00:00<00:07, 28.06it/s]\u001b[A\n",
      "Applying IIR:   6%|         | 13/225 [00:00<00:07, 28.15it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 16/225 [00:00<00:07, 28.28it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 19/225 [00:00<00:07, 27.62it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 22/225 [00:00<00:07, 27.11it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 25/225 [00:00<00:07, 25.96it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 28/225 [00:01<00:07, 25.29it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 31/225 [00:01<00:07, 25.32it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 34/225 [00:01<00:07, 24.40it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 37/225 [00:01<00:07, 24.43it/s]\u001b[A\n",
      "Applying IIR:  18%|        | 40/225 [00:01<00:07, 25.52it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 44/225 [00:01<00:06, 26.90it/s]\u001b[A\n",
      "Applying IIR:  21%|        | 47/225 [00:01<00:06, 27.57it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 51/225 [00:01<00:06, 28.34it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:02<00:05, 28.73it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:02<00:06, 26.55it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 61/225 [00:02<00:05, 28.12it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 64/225 [00:02<00:05, 28.18it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 67/225 [00:02<00:06, 25.84it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 70/225 [00:02<00:06, 25.36it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 73/225 [00:02<00:05, 25.60it/s]\u001b[A\n",
      "Applying IIR:  34%|      | 76/225 [00:02<00:05, 24.96it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 79/225 [00:02<00:05, 25.82it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 82/225 [00:03<00:05, 26.83it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 85/225 [00:03<00:05, 27.53it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 88/225 [00:03<00:04, 27.68it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 91/225 [00:03<00:04, 27.68it/s]\u001b[A\n",
      "Applying IIR:  42%|     | 94/225 [00:03<00:04, 27.47it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 97/225 [00:03<00:05, 25.49it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 100/225 [00:03<00:05, 23.77it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 103/225 [00:03<00:05, 24.13it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 106/225 [00:04<00:04, 24.33it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 109/225 [00:04<00:04, 24.24it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 112/225 [00:04<00:04, 23.99it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 115/225 [00:04<00:04, 24.64it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 118/225 [00:04<00:04, 25.73it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 121/225 [00:04<00:04, 25.87it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 124/225 [00:04<00:03, 26.83it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 127/225 [00:04<00:03, 25.41it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 130/225 [00:04<00:03, 24.96it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 133/225 [00:05<00:03, 23.99it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 136/225 [00:05<00:03, 23.11it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 139/225 [00:05<00:03, 22.96it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 142/225 [00:05<00:03, 22.74it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 145/225 [00:05<00:03, 23.27it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 148/225 [00:05<00:03, 23.51it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 151/225 [00:05<00:03, 24.29it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 154/225 [00:06<00:02, 24.13it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 157/225 [00:06<00:02, 24.29it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 160/225 [00:06<00:02, 25.57it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 163/225 [00:06<00:02, 26.39it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 166/225 [00:06<00:02, 26.10it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 169/225 [00:06<00:02, 25.97it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 172/225 [00:06<00:01, 26.63it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 175/225 [00:06<00:01, 27.12it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 178/225 [00:06<00:01, 26.92it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 181/225 [00:07<00:01, 24.80it/s]\u001b[A\n",
      "Applying IIR:  82%| | 184/225 [00:07<00:01, 25.22it/s]\u001b[A\n",
      "Applying IIR:  83%| | 187/225 [00:07<00:01, 25.33it/s]\u001b[A\n",
      "Applying IIR:  84%| | 190/225 [00:07<00:01, 24.88it/s]\u001b[A\n",
      "Applying IIR:  86%| | 193/225 [00:07<00:01, 25.00it/s]\u001b[A\n",
      "Applying IIR:  87%| | 196/225 [00:07<00:01, 24.43it/s]\u001b[A\n",
      "Applying IIR:  88%| | 199/225 [00:07<00:01, 23.34it/s]\u001b[A\n",
      "Applying IIR:  90%| | 202/225 [00:07<00:00, 23.31it/s]\u001b[A\n",
      "Applying IIR:  91%| | 205/225 [00:08<00:00, 23.93it/s]\u001b[A\n",
      "Applying IIR:  92%|| 208/225 [00:08<00:00, 23.55it/s]\u001b[A\n",
      "Applying IIR:  94%|| 211/225 [00:08<00:00, 23.64it/s]\u001b[A\n",
      "Applying IIR:  95%|| 214/225 [00:08<00:00, 24.57it/s]\u001b[A\n",
      "Applying IIR:  96%|| 217/225 [00:08<00:00, 25.83it/s]\u001b[A\n",
      "Applying IIR:  98%|| 220/225 [00:08<00:00, 26.44it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 25.59it/s]\u001b[A\n",
      " 76%|  | 16/21 [02:16<00:42,  8.56s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:09, 22.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1260311_1916010_B_002.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1260311_1916010_B_002.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:09, 22.64it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:09, 23.39it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:08, 24.58it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:08, 23.85it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:09, 22.95it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:08, 23.57it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 24/225 [00:01<00:08, 24.26it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/225 [00:01<00:08, 24.06it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 30/225 [00:01<00:08, 22.29it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/225 [00:01<00:08, 21.59it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/225 [00:01<00:08, 22.31it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 39/225 [00:01<00:08, 23.20it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/225 [00:01<00:07, 24.41it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 45/225 [00:01<00:07, 24.75it/s]\u001b[A\n",
      "Applying IIR:  21%|       | 48/225 [00:02<00:07, 24.76it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 51/225 [00:02<00:06, 25.43it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:02<00:06, 26.34it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:02<00:06, 27.17it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 60/225 [00:02<00:05, 27.93it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 63/225 [00:02<00:05, 27.76it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 66/225 [00:02<00:06, 26.11it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 69/225 [00:02<00:06, 25.86it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 72/225 [00:02<00:05, 25.89it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 75/225 [00:03<00:05, 26.28it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 78/225 [00:03<00:05, 27.17it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 81/225 [00:03<00:05, 27.39it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 84/225 [00:03<00:05, 27.74it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 87/225 [00:03<00:04, 27.93it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 90/225 [00:03<00:04, 27.26it/s]\u001b[A\n",
      "Applying IIR:  41%|     | 93/225 [00:03<00:04, 27.79it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 97/225 [00:03<00:04, 28.55it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 100/225 [00:03<00:04, 28.94it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 103/225 [00:04<00:04, 28.09it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 107/225 [00:04<00:04, 29.49it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 110/225 [00:04<00:03, 29.60it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 114/225 [00:04<00:03, 30.30it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 118/225 [00:04<00:03, 31.11it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 122/225 [00:04<00:03, 31.32it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 126/225 [00:04<00:03, 31.50it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 130/225 [00:04<00:03, 28.97it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 134/225 [00:05<00:03, 29.32it/s]\u001b[A\n",
      "Applying IIR:  61%|    | 137/225 [00:05<00:03, 27.18it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 140/225 [00:05<00:03, 27.51it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 144/225 [00:05<00:02, 28.66it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 148/225 [00:05<00:02, 29.83it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 152/225 [00:05<00:02, 28.50it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 155/225 [00:05<00:02, 25.18it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 158/225 [00:05<00:02, 25.53it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 161/225 [00:06<00:02, 23.87it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 165/225 [00:06<00:02, 25.92it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 169/225 [00:06<00:02, 27.05it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 173/225 [00:06<00:01, 28.80it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 176/225 [00:06<00:01, 27.58it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 179/225 [00:06<00:01, 27.43it/s]\u001b[A\n",
      "Applying IIR:  81%| | 183/225 [00:06<00:01, 28.78it/s]\u001b[A\n",
      "Applying IIR:  83%| | 187/225 [00:06<00:01, 30.02it/s]\u001b[A\n",
      "Applying IIR:  85%| | 191/225 [00:07<00:01, 30.90it/s]\u001b[A\n",
      "Applying IIR:  87%| | 195/225 [00:07<00:01, 27.94it/s]\u001b[A\n",
      "Applying IIR:  88%| | 198/225 [00:07<00:00, 28.00it/s]\u001b[A\n",
      "Applying IIR:  89%| | 201/225 [00:07<00:00, 26.87it/s]\u001b[A\n",
      "Applying IIR:  91%| | 204/225 [00:07<00:00, 24.46it/s]\u001b[A\n",
      "Applying IIR:  92%|| 208/225 [00:07<00:00, 26.17it/s]\u001b[A\n",
      "Applying IIR:  94%|| 211/225 [00:07<00:00, 25.91it/s]\u001b[A\n",
      "Applying IIR:  96%|| 215/225 [00:07<00:00, 26.84it/s]\u001b[A\n",
      "Applying IIR:  97%|| 218/225 [00:08<00:00, 25.67it/s]\u001b[A\n",
      "Applying IIR:  98%|| 221/225 [00:08<00:00, 26.56it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 26.99it/s]\u001b[A\n",
      " 81%|  | 17/21 [02:25<00:34,  8.56s/it]\n",
      "Applying IIR:   0%|          | 0/220 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/220 [00:00<00:09, 22.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1260311_1916010_B_003.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1260311_1916010_B_003.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/220 [00:00<00:09, 23.29it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 10/220 [00:00<00:08, 25.36it/s]\u001b[A\n",
      "Applying IIR:   6%|         | 14/220 [00:00<00:07, 26.73it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 17/220 [00:00<00:07, 27.19it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 21/220 [00:00<00:07, 28.34it/s]\u001b[A\n",
      "Applying IIR:  11%|        | 25/220 [00:00<00:06, 28.50it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 28/220 [00:00<00:06, 27.94it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 31/220 [00:01<00:06, 28.46it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 35/220 [00:01<00:06, 29.86it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 38/220 [00:01<00:06, 29.47it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/220 [00:01<00:05, 30.29it/s]\u001b[A\n",
      "Applying IIR:  21%|        | 46/220 [00:01<00:05, 31.01it/s]\u001b[A\n",
      "Applying IIR:  23%|       | 50/220 [00:01<00:05, 31.77it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 54/220 [00:01<00:05, 32.03it/s]\u001b[A\n",
      "Applying IIR:  26%|       | 58/220 [00:01<00:05, 32.35it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 62/220 [00:02<00:05, 29.16it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 65/220 [00:02<00:05, 27.88it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 68/220 [00:02<00:05, 27.67it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 71/220 [00:02<00:05, 27.80it/s]\u001b[A\n",
      "Applying IIR:  34%|      | 74/220 [00:02<00:05, 27.31it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 77/220 [00:02<00:05, 26.56it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 80/220 [00:02<00:05, 26.43it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 83/220 [00:02<00:05, 25.37it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 86/220 [00:03<00:05, 26.51it/s]\u001b[A\n",
      "Applying IIR:  41%|      | 90/220 [00:03<00:04, 27.65it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 94/220 [00:03<00:04, 29.08it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 98/220 [00:03<00:04, 29.22it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 101/220 [00:03<00:04, 26.79it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 104/220 [00:03<00:04, 26.13it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 107/220 [00:03<00:04, 25.79it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 111/220 [00:03<00:04, 27.22it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 115/220 [00:04<00:03, 28.31it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 118/220 [00:04<00:03, 27.61it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 121/220 [00:04<00:03, 27.90it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 124/220 [00:04<00:03, 28.17it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 127/220 [00:04<00:03, 27.30it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 130/220 [00:04<00:03, 27.10it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 133/220 [00:04<00:03, 26.59it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 136/220 [00:04<00:03, 27.24it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 139/220 [00:04<00:02, 27.22it/s]\u001b[A\n",
      "Applying IIR:  65%|   | 142/220 [00:05<00:02, 26.82it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 145/220 [00:05<00:02, 26.85it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 148/220 [00:05<00:02, 26.22it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 151/220 [00:05<00:02, 25.02it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 154/220 [00:05<00:02, 24.75it/s]\u001b[A\n",
      "Applying IIR:  71%|  | 157/220 [00:05<00:02, 23.96it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 160/220 [00:05<00:02, 23.58it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 163/220 [00:05<00:02, 22.77it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 166/220 [00:06<00:02, 22.67it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 169/220 [00:06<00:02, 22.33it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 172/220 [00:06<00:02, 23.32it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 175/220 [00:06<00:01, 23.47it/s]\u001b[A\n",
      "Applying IIR:  81%|  | 178/220 [00:06<00:01, 23.34it/s]\u001b[A\n",
      "Applying IIR:  82%| | 181/220 [00:06<00:01, 23.84it/s]\u001b[A\n",
      "Applying IIR:  84%| | 184/220 [00:06<00:01, 23.92it/s]\u001b[A\n",
      "Applying IIR:  85%| | 187/220 [00:06<00:01, 24.49it/s]\u001b[A\n",
      "Applying IIR:  86%| | 190/220 [00:07<00:01, 24.65it/s]\u001b[A\n",
      "Applying IIR:  88%| | 193/220 [00:07<00:01, 25.72it/s]\u001b[A\n",
      "Applying IIR:  89%| | 196/220 [00:07<00:00, 25.01it/s]\u001b[A\n",
      "Applying IIR:  90%| | 199/220 [00:07<00:00, 25.56it/s]\u001b[A\n",
      "Applying IIR:  92%|| 202/220 [00:07<00:00, 25.32it/s]\u001b[A\n",
      "Applying IIR:  93%|| 205/220 [00:07<00:00, 26.22it/s]\u001b[A\n",
      "Applying IIR:  95%|| 208/220 [00:07<00:00, 25.83it/s]\u001b[A\n",
      "Applying IIR:  96%|| 211/220 [00:07<00:00, 25.87it/s]\u001b[A\n",
      "Applying IIR:  97%|| 214/220 [00:07<00:00, 26.76it/s]\u001b[A\n",
      "Applying IIR: 100%|| 220/220 [00:08<00:00, 26.97it/s]\u001b[A\n",
      " 86%| | 18/21 [02:33<00:25,  8.52s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:08, 26.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1941250_1916010_B_001.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1941250_1916010_B_001.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:08, 27.19it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:07, 27.48it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:07, 27.88it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:07, 28.29it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:07, 28.28it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 21/225 [00:00<00:07, 28.14it/s]\u001b[A\n",
      "Applying IIR:  11%|         | 25/225 [00:00<00:06, 28.92it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 29/225 [00:01<00:06, 29.62it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 32/225 [00:01<00:06, 28.35it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 35/225 [00:01<00:06, 28.40it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 38/225 [00:01<00:06, 27.11it/s]\u001b[A\n",
      "Applying IIR:  18%|        | 41/225 [00:01<00:06, 27.47it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 44/225 [00:01<00:07, 25.55it/s]\u001b[A\n",
      "Applying IIR:  21%|        | 47/225 [00:01<00:06, 25.65it/s]\u001b[A\n",
      "Applying IIR:  22%|       | 50/225 [00:01<00:06, 26.15it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 53/225 [00:01<00:06, 25.95it/s]\u001b[A\n",
      "Applying IIR:  25%|       | 57/225 [00:02<00:06, 27.21it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 61/225 [00:02<00:05, 28.15it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 64/225 [00:02<00:06, 25.94it/s]\u001b[A\n",
      "Applying IIR:  30%|       | 67/225 [00:02<00:06, 25.72it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 70/225 [00:02<00:06, 24.93it/s]\u001b[A\n",
      "Applying IIR:  32%|      | 73/225 [00:02<00:05, 25.89it/s]\u001b[A\n",
      "Applying IIR:  34%|      | 76/225 [00:02<00:05, 26.50it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 79/225 [00:02<00:05, 26.95it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 82/225 [00:03<00:05, 27.55it/s]\u001b[A\n",
      "Applying IIR:  38%|      | 85/225 [00:03<00:05, 27.71it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 88/225 [00:03<00:04, 27.62it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 91/225 [00:03<00:04, 27.65it/s]\u001b[A\n",
      "Applying IIR:  42%|     | 95/225 [00:03<00:04, 28.61it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 98/225 [00:03<00:04, 27.95it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 101/225 [00:03<00:04, 26.84it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 104/225 [00:03<00:04, 26.82it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 107/225 [00:03<00:04, 27.09it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 110/225 [00:04<00:04, 27.34it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 113/225 [00:04<00:04, 27.18it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 116/225 [00:04<00:04, 27.14it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 119/225 [00:04<00:04, 26.39it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 122/225 [00:04<00:03, 26.63it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 125/225 [00:04<00:03, 27.03it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 128/225 [00:04<00:03, 26.47it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 131/225 [00:04<00:03, 27.03it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 135/225 [00:04<00:03, 28.31it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 139/225 [00:05<00:02, 29.26it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 142/225 [00:05<00:02, 28.43it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 145/225 [00:05<00:02, 27.95it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 149/225 [00:05<00:02, 29.09it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 152/225 [00:05<00:02, 27.12it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 156/225 [00:05<00:02, 28.37it/s]\u001b[A\n",
      "Applying IIR:  71%|   | 160/225 [00:05<00:02, 29.50it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 163/225 [00:05<00:02, 29.64it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 167/225 [00:05<00:01, 31.06it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 171/225 [00:06<00:01, 28.32it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 174/225 [00:06<00:01, 28.80it/s]\u001b[A\n",
      "Applying IIR:  79%|  | 177/225 [00:06<00:01, 26.52it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 180/225 [00:06<00:01, 25.54it/s]\u001b[A\n",
      "Applying IIR:  81%| | 183/225 [00:06<00:01, 24.56it/s]\u001b[A\n",
      "Applying IIR:  83%| | 186/225 [00:06<00:01, 24.25it/s]\u001b[A\n",
      "Applying IIR:  84%| | 189/225 [00:06<00:01, 24.52it/s]\u001b[A\n",
      "Applying IIR:  85%| | 192/225 [00:07<00:01, 24.15it/s]\u001b[A\n",
      "Applying IIR:  87%| | 195/225 [00:07<00:01, 25.25it/s]\u001b[A\n",
      "Applying IIR:  88%| | 198/225 [00:07<00:01, 26.15it/s]\u001b[A\n",
      "Applying IIR:  89%| | 201/225 [00:07<00:00, 26.87it/s]\u001b[A\n",
      "Applying IIR:  91%| | 204/225 [00:07<00:00, 25.76it/s]\u001b[A\n",
      "Applying IIR:  92%|| 207/225 [00:07<00:00, 25.80it/s]\u001b[A\n",
      "Applying IIR:  93%|| 210/225 [00:07<00:00, 26.88it/s]\u001b[A\n",
      "Applying IIR:  95%|| 213/225 [00:07<00:00, 27.12it/s]\u001b[A\n",
      "Applying IIR:  96%|| 216/225 [00:07<00:00, 26.46it/s]\u001b[A\n",
      "Applying IIR:  97%|| 219/225 [00:08<00:00, 25.96it/s]\u001b[A\n",
      "Applying IIR:  99%|| 222/225 [00:08<00:00, 25.89it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 27.13it/s]\u001b[A\n",
      " 90%| | 19/21 [02:42<00:17,  8.53s/it]\n",
      "Applying IIR:   0%|          | 0/222 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/222 [00:00<00:07, 27.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 1853436_1916010_B_003.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/1853436_1916010_B_003.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/222 [00:00<00:07, 27.95it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/222 [00:00<00:07, 26.69it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/222 [00:00<00:07, 27.24it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/222 [00:00<00:07, 27.80it/s]\u001b[A\n",
      "Applying IIR:   9%|         | 19/222 [00:00<00:07, 28.65it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 23/222 [00:00<00:06, 29.56it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 27/222 [00:00<00:06, 30.32it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 30/222 [00:01<00:07, 26.93it/s]\u001b[A\n",
      "Applying IIR:  15%|        | 33/222 [00:01<00:07, 26.21it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 36/222 [00:01<00:07, 26.18it/s]\u001b[A\n",
      "Applying IIR:  18%|        | 39/222 [00:01<00:07, 23.73it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/222 [00:01<00:07, 23.63it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 45/222 [00:01<00:07, 24.97it/s]\u001b[A\n",
      "Applying IIR:  22%|       | 49/222 [00:01<00:06, 26.35it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 53/222 [00:01<00:05, 28.22it/s]\u001b[A\n",
      "Applying IIR:  26%|       | 57/222 [00:02<00:05, 29.45it/s]\u001b[A\n",
      "Applying IIR:  27%|       | 61/222 [00:02<00:05, 29.68it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 65/222 [00:02<00:05, 30.89it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 69/222 [00:02<00:04, 31.08it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 73/222 [00:02<00:04, 29.98it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 77/222 [00:02<00:05, 28.41it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 80/222 [00:02<00:04, 28.56it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 83/222 [00:02<00:04, 28.03it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 86/222 [00:03<00:04, 27.48it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 89/222 [00:03<00:05, 26.53it/s]\u001b[A\n",
      "Applying IIR:  41%|     | 92/222 [00:03<00:05, 25.97it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 95/222 [00:03<00:05, 25.17it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 98/222 [00:03<00:04, 25.54it/s]\u001b[A\n",
      "Applying IIR:  45%|     | 101/222 [00:03<00:04, 24.43it/s]\u001b[A\n",
      "Applying IIR:  47%|     | 104/222 [00:03<00:04, 24.61it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 107/222 [00:03<00:04, 23.58it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 110/222 [00:04<00:04, 23.59it/s]\u001b[A\n",
      "Applying IIR:  51%|     | 113/222 [00:04<00:04, 23.80it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 116/222 [00:04<00:04, 25.06it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 119/222 [00:04<00:04, 25.56it/s]\u001b[A\n",
      "Applying IIR:  55%|    | 122/222 [00:04<00:03, 25.66it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 125/222 [00:04<00:03, 24.86it/s]\u001b[A\n",
      "Applying IIR:  58%|    | 128/222 [00:04<00:04, 23.24it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 131/222 [00:04<00:04, 22.16it/s]\u001b[A\n",
      "Applying IIR:  60%|    | 134/222 [00:05<00:03, 22.80it/s]\u001b[A\n",
      "Applying IIR:  62%|   | 137/222 [00:05<00:03, 22.06it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 140/222 [00:05<00:03, 22.84it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 143/222 [00:05<00:03, 23.59it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 146/222 [00:05<00:03, 24.02it/s]\u001b[A\n",
      "Applying IIR:  67%|   | 149/222 [00:05<00:03, 22.48it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 152/222 [00:05<00:03, 22.62it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 155/222 [00:05<00:02, 24.31it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 159/222 [00:06<00:02, 26.02it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 162/222 [00:06<00:02, 26.73it/s]\u001b[A\n",
      "Applying IIR:  75%|  | 166/222 [00:06<00:01, 28.61it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 170/222 [00:06<00:01, 29.98it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 174/222 [00:06<00:01, 30.76it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 178/222 [00:06<00:01, 31.62it/s]\u001b[A\n",
      "Applying IIR:  82%| | 182/222 [00:06<00:01, 32.03it/s]\u001b[A\n",
      "Applying IIR:  84%| | 186/222 [00:06<00:01, 32.19it/s]\u001b[A\n",
      "Applying IIR:  86%| | 190/222 [00:07<00:00, 32.57it/s]\u001b[A\n",
      "Applying IIR:  87%| | 194/222 [00:07<00:00, 33.14it/s]\u001b[A\n",
      "Applying IIR:  89%| | 198/222 [00:07<00:00, 33.03it/s]\u001b[A\n",
      "Applying IIR:  91%| | 202/222 [00:07<00:00, 33.19it/s]\u001b[A\n",
      "Applying IIR:  93%|| 206/222 [00:07<00:00, 33.63it/s]\u001b[A\n",
      "Applying IIR:  95%|| 210/222 [00:07<00:00, 33.62it/s]\u001b[A\n",
      "Applying IIR:  96%|| 214/222 [00:07<00:00, 33.06it/s]\u001b[A\n",
      "Applying IIR:  98%|| 218/222 [00:07<00:00, 31.18it/s]\u001b[A\n",
      "Applying IIR: 100%|| 222/222 [00:08<00:00, 27.52it/s]\u001b[A\n",
      " 95%|| 20/21 [02:50<00:08,  8.46s/it]\n",
      "Applying IIR:   0%|          | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Applying IIR:   1%|         | 3/225 [00:00<00:09, 24.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motion mag for vid: 2059066_1916010_B_002.mp4\n",
      "video ../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops/2059066_1916010_B_002.mp4\n",
      "\n",
      "Iteration number is 259002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying IIR:   3%|         | 6/225 [00:00<00:09, 24.03it/s]\u001b[A\n",
      "Applying IIR:   4%|         | 9/225 [00:00<00:08, 24.26it/s]\u001b[A\n",
      "Applying IIR:   5%|         | 12/225 [00:00<00:08, 24.68it/s]\u001b[A\n",
      "Applying IIR:   7%|         | 15/225 [00:00<00:08, 25.70it/s]\u001b[A\n",
      "Applying IIR:   8%|         | 18/225 [00:00<00:08, 25.53it/s]\u001b[A\n",
      "Applying IIR:  10%|         | 22/225 [00:00<00:07, 27.00it/s]\u001b[A\n",
      "Applying IIR:  12%|        | 26/225 [00:00<00:07, 28.24it/s]\u001b[A\n",
      "Applying IIR:  13%|        | 29/225 [00:01<00:06, 28.59it/s]\u001b[A\n",
      "Applying IIR:  14%|        | 32/225 [00:01<00:07, 26.60it/s]\u001b[A\n",
      "Applying IIR:  16%|        | 35/225 [00:01<00:07, 26.84it/s]\u001b[A\n",
      "Applying IIR:  17%|        | 38/225 [00:01<00:06, 27.28it/s]\u001b[A\n",
      "Applying IIR:  19%|        | 42/225 [00:01<00:06, 28.68it/s]\u001b[A\n",
      "Applying IIR:  20%|        | 46/225 [00:01<00:05, 30.03it/s]\u001b[A\n",
      "Applying IIR:  22%|       | 50/225 [00:01<00:05, 31.34it/s]\u001b[A\n",
      "Applying IIR:  24%|       | 54/225 [00:01<00:05, 32.08it/s]\u001b[A\n",
      "Applying IIR:  26%|       | 58/225 [00:02<00:05, 32.67it/s]\u001b[A\n",
      "Applying IIR:  28%|       | 62/225 [00:02<00:05, 32.57it/s]\u001b[A\n",
      "Applying IIR:  29%|       | 66/225 [00:02<00:04, 32.90it/s]\u001b[A\n",
      "Applying IIR:  31%|       | 70/225 [00:02<00:04, 31.82it/s]\u001b[A\n",
      "Applying IIR:  33%|      | 74/225 [00:02<00:05, 29.87it/s]\u001b[A\n",
      "Applying IIR:  35%|      | 78/225 [00:02<00:05, 29.01it/s]\u001b[A\n",
      "Applying IIR:  36%|      | 81/225 [00:02<00:05, 28.72it/s]\u001b[A\n",
      "Applying IIR:  37%|      | 84/225 [00:02<00:04, 28.70it/s]\u001b[A\n",
      "Applying IIR:  39%|      | 87/225 [00:03<00:04, 28.69it/s]\u001b[A\n",
      "Applying IIR:  40%|      | 90/225 [00:03<00:04, 27.94it/s]\u001b[A\n",
      "Applying IIR:  41%|     | 93/225 [00:03<00:05, 26.11it/s]\u001b[A\n",
      "Applying IIR:  43%|     | 96/225 [00:03<00:05, 25.03it/s]\u001b[A\n",
      "Applying IIR:  44%|     | 100/225 [00:03<00:04, 26.54it/s]\u001b[A\n",
      "Applying IIR:  46%|     | 104/225 [00:03<00:04, 27.79it/s]\u001b[A\n",
      "Applying IIR:  48%|     | 107/225 [00:03<00:04, 25.61it/s]\u001b[A\n",
      "Applying IIR:  49%|     | 110/225 [00:03<00:04, 25.42it/s]\u001b[A\n",
      "Applying IIR:  50%|     | 113/225 [00:04<00:04, 26.11it/s]\u001b[A\n",
      "Applying IIR:  52%|    | 116/225 [00:04<00:04, 25.07it/s]\u001b[A\n",
      "Applying IIR:  53%|    | 119/225 [00:04<00:04, 25.50it/s]\u001b[A\n",
      "Applying IIR:  54%|    | 122/225 [00:04<00:04, 24.59it/s]\u001b[A\n",
      "Applying IIR:  56%|    | 125/225 [00:04<00:04, 24.72it/s]\u001b[A\n",
      "Applying IIR:  57%|    | 129/225 [00:04<00:03, 26.53it/s]\u001b[A\n",
      "Applying IIR:  59%|    | 133/225 [00:04<00:03, 28.29it/s]\u001b[A\n",
      "Applying IIR:  61%|    | 137/225 [00:04<00:02, 29.95it/s]\u001b[A\n",
      "Applying IIR:  63%|   | 141/225 [00:04<00:02, 30.63it/s]\u001b[A\n",
      "Applying IIR:  64%|   | 145/225 [00:05<00:02, 31.41it/s]\u001b[A\n",
      "Applying IIR:  66%|   | 149/225 [00:05<00:02, 27.88it/s]\u001b[A\n",
      "Applying IIR:  68%|   | 152/225 [00:05<00:02, 25.16it/s]\u001b[A\n",
      "Applying IIR:  69%|   | 155/225 [00:05<00:02, 24.52it/s]\u001b[A\n",
      "Applying IIR:  70%|   | 158/225 [00:05<00:02, 24.34it/s]\u001b[A\n",
      "Applying IIR:  72%|  | 161/225 [00:05<00:02, 25.30it/s]\u001b[A\n",
      "Applying IIR:  73%|  | 164/225 [00:05<00:02, 25.60it/s]\u001b[A\n",
      "Applying IIR:  74%|  | 167/225 [00:06<00:02, 24.94it/s]\u001b[A\n",
      "Applying IIR:  76%|  | 170/225 [00:06<00:02, 23.55it/s]\u001b[A\n",
      "Applying IIR:  77%|  | 173/225 [00:06<00:02, 23.67it/s]\u001b[A\n",
      "Applying IIR:  78%|  | 176/225 [00:06<00:02, 23.26it/s]\u001b[A\n",
      "Applying IIR:  80%|  | 179/225 [00:06<00:01, 23.83it/s]\u001b[A\n",
      "Applying IIR:  81%|  | 182/225 [00:06<00:01, 24.22it/s]\u001b[A\n",
      "Applying IIR:  82%| | 185/225 [00:06<00:01, 24.72it/s]\u001b[A\n",
      "Applying IIR:  84%| | 188/225 [00:06<00:01, 24.61it/s]\u001b[A\n",
      "Applying IIR:  85%| | 191/225 [00:07<00:01, 25.12it/s]\u001b[A\n",
      "Applying IIR:  86%| | 194/225 [00:07<00:01, 26.34it/s]\u001b[A\n",
      "Applying IIR:  88%| | 198/225 [00:07<00:00, 27.73it/s]\u001b[A\n",
      "Applying IIR:  89%| | 201/225 [00:07<00:00, 26.44it/s]\u001b[A\n",
      "Applying IIR:  91%| | 204/225 [00:07<00:00, 26.49it/s]\u001b[A\n",
      "Applying IIR:  92%|| 207/225 [00:07<00:00, 26.92it/s]\u001b[A\n",
      "Applying IIR:  93%|| 210/225 [00:07<00:00, 25.98it/s]\u001b[A\n",
      "Applying IIR:  95%|| 213/225 [00:07<00:00, 24.18it/s]\u001b[A\n",
      "Applying IIR:  96%|| 216/225 [00:07<00:00, 24.10it/s]\u001b[A\n",
      "Applying IIR:  97%|| 219/225 [00:08<00:00, 25.39it/s]\u001b[A\n",
      "Applying IIR:  99%|| 222/225 [00:08<00:00, 26.34it/s]\u001b[A\n",
      "Applying IIR: 100%|| 225/225 [00:08<00:00, 27.01it/s]\u001b[A\n",
      "100%|| 21/21 [02:59<00:00,  8.54s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def run_motion_mag_all_folders(base_dirs, config_spec, config_file):\n",
    "    configspec = ConfigObj(config_spec, raise_errors=True)\n",
    "    config = ConfigObj(config_file,\n",
    "                       configspec=configspec,\n",
    "                       raise_errors=True,\n",
    "                       file_error=True)\n",
    "    \n",
    "    # Validate to get all the default values.\n",
    "    config.validate(Validator())\n",
    "    \n",
    "    network_type = 'ynet_3frames'\n",
    "    exp_name = '%(dataset)s_%(variant)s'\n",
    "    setproctitle.setproctitle(exp_name)\n",
    "    tfconfig = tf.ConfigProto(allow_soft_placement=True,\n",
    "                              log_device_placement=False)\n",
    "    tfconfig.gpu_options.allow_growth = True\n",
    "    \n",
    "    with tf.Session(config=tfconfig) as sess:\n",
    "        model = MagNet3Frames(sess, exp_name, config['architecture'])\n",
    "        checkpoint = '../deep_motion_mag/data/training/o3f_hmhm2_bg_qnoise_mix4_nl_n_t_ds3/checkpoint'\n",
    "        for bd in base_dirs:\n",
    "            print(\"Magnifying vids in\", bd)\n",
    "            for vid in tqdm(os.listdir(bd)):\n",
    "                print('running motion mag for vid:',vid)\n",
    "                input_folder = os.path.join(bd,vid)\n",
    "                output_folder = os.path.join(bd + '_mm', vid)\n",
    "#                 os.makedirs(output_folder, exist_ok=True)\n",
    "                run_motion_mag_one_video(model, checkpoint, 'run_temporal', input_folder, output_folder)\n",
    "            \n",
    "    \n",
    "def run_motion_mag_one_video(model, checkpoint, phase, video, output):\n",
    "    \n",
    "    print('video',video)\n",
    "    print()\n",
    "    amplification_factor = 4\n",
    "    velocity_mag = True\n",
    "    fl = 0.5\n",
    "    fh = 1\n",
    "    fs = 30\n",
    "    n_filter_tap = 2 \n",
    "    filter_type = 'differenceOfIIR'\n",
    "    \n",
    "    if phase == 'run':\n",
    "        model.run(checkpoint,\n",
    "                  video,\n",
    "                  'jpg',\n",
    "                  output,\n",
    "                  amplification_factor,\n",
    "                  velocity_mag)\n",
    "        \n",
    "    elif phase == 'run_temporal':\n",
    "        model.run_temporal(checkpoint,\n",
    "                           video,\n",
    "                           'jpg',\n",
    "                           output,\n",
    "                           amplification_factor,\n",
    "                           fl,\n",
    "                           fh,\n",
    "                           fs,\n",
    "                           n_filter_tap,\n",
    "                           filter_type,\n",
    "                          fixed_size=256)    \n",
    "        \n",
    "exp_name= 'o3f_hmhm2_bg_qnoise_mix4_nl_n_t_ds3'\n",
    "config_file = '../deep_motion_mag/configs/'+exp_name+'.conf'\n",
    "config_spec = '../deep_motion_mag/configs/configspec.conf'\n",
    "base_dirs = ['../../deepfake_data/fb_dfd_release_0.1_final/method_B_crops']\n",
    "run_motion_mag_all_folders(base_dirs, config_spec, config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting faces for 2090100_B_002.mp4\n",
      "Extracting faces for 2090100_C_003.mp4\n",
      "Extracting faces for 2090100_D_001.mp4\n",
      "Extracting faces for 2090100_B_003.mp4\n",
      "Extracting faces for 2090100_A_001.mp4\n",
      "Extracting faces for 2090100_C_002.mp4\n",
      "Extracting faces for 2090100_D_003.mp4\n",
      "Extracting faces for 2090100_C_001.mp4\n",
      "Extracting faces for 2090100_A_002.mp4\n",
      "Extracting faces for 2090100_D_002.mp4\n",
      "Extracting faces for 2090100_A_003.mp4\n",
      "Extracting faces for 2090100_B_001.mp4\n",
      "Extracting faces for 1569101_G_002.mp4\n",
      "Extracting faces for 1569101_C_002.mp4\n",
      "Extracting faces for 1569101_K_002.mp4\n",
      "Extracting faces for 1569101_F_003.mp4\n",
      "Extracting faces for 1569101_B_003.mp4\n",
      "Extracting faces for 1569101_J_003.mp4\n",
      "Extracting faces for 1569101_I_001.mp4\n",
      "Extracting faces for 1569101_E_001.mp4\n",
      "Extracting faces for 1569101_A_001.mp4\n",
      "Extracting faces for 1569101_K_003.mp4\n",
      "Extracting faces for 1569101_G_003.mp4\n",
      "Extracting faces for 1569101_C_003.mp4\n",
      "Extracting faces for 1569101_D_001.mp4\n",
      "Extracting faces for 1569101_H_001.mp4\n",
      "Extracting faces for 1569101_J_002.mp4\n",
      "Extracting faces for 1569101_F_002.mp4\n",
      "Extracting faces for 1569101_B_002.mp4\n",
      "Extracting faces for 1569101_I_003.mp4\n",
      "Extracting faces for 1569101_E_003.mp4\n",
      "Extracting faces for 1569101_A_003.mp4\n",
      "Extracting faces for 1569101_F_001.mp4\n",
      "Extracting faces for 1569101_B_001.mp4\n",
      "Extracting faces for 1569101_J_001.mp4\n",
      "Extracting faces for 1569101_H_002.mp4\n",
      "Extracting faces for 1569101_D_002.mp4\n",
      "Extracting faces for 1569101_E_002.mp4\n",
      "Extracting faces for 1569101_A_002.mp4\n",
      "Extracting faces for 1569101_I_002.mp4\n",
      "Extracting faces for 1569101_D_003.mp4\n",
      "Extracting faces for 1569101_H_003.mp4\n",
      "Extracting faces for 1569101_K_001.mp4\n",
      "Extracting faces for 1569101_G_001.mp4\n",
      "Extracting faces for 1569101_C_001.mp4\n",
      "Extracting faces for 1645928_A_001.mp4\n",
      "Extracting faces for 1645928_A_003.mp4\n",
      "Extracting faces for 1645928_A_002.mp4\n",
      "Extracting faces for 1851350_A_003.mp4\n",
      "Extracting faces for 1851350_B_001.mp4\n",
      "Extracting faces for 1851350_A_002.mp4\n",
      "Extracting faces for 1851350_C_001.mp4\n",
      "Extracting faces for 1851350_C_002.mp4\n",
      "Extracting faces for 1851350_B_003.mp4\n",
      "Extracting faces for 1851350_A_001.mp4\n",
      "Extracting faces for 1851350_C_003.mp4\n",
      "Extracting faces for 1851350_B_002.mp4\n",
      "Extracting faces for 2060058_C_003.mp4\n",
      "Extracting faces for 2060058_B_002.mp4\n",
      "Extracting faces for 2060058_C_002.mp4\n",
      "Extracting faces for 2060058_A_001.mp4\n",
      "Extracting faces for 2060058_B_003.mp4\n",
      "Extracting faces for 2060058_A_002.mp4\n",
      "Extracting faces for 2060058_C_001.mp4\n",
      "Extracting faces for 2060058_B_001.mp4\n",
      "Extracting faces for 2060058_A_003.mp4\n",
      "Extracting faces for 1941250_J_003.mp4\n",
      "Extracting faces for 1941250_F_003.mp4\n",
      "Extracting faces for 1941250_B_003.mp4\n",
      "Extracting faces for 1941250_E_001.mp4\n",
      "Extracting faces for 1941250_A_001.mp4\n",
      "Extracting faces for 1941250_I_001.mp4\n",
      "Extracting faces for 1941250_G_002.mp4\n",
      "Extracting faces for 1941250_C_002.mp4\n",
      "Extracting faces for 1941250_F_002.mp4\n",
      "Extracting faces for 1941250_B_002.mp4\n",
      "Extracting faces for 1941250_J_002.mp4\n",
      "Extracting faces for 1941250_G_003.mp4\n",
      "Extracting faces for 1941250_C_003.mp4\n",
      "Extracting faces for 1941250_H_001.mp4\n",
      "Extracting faces for 1941250_D_001.mp4\n",
      "Extracting faces for 1941250_D_002.mp4\n",
      "Extracting faces for 1941250_H_002.mp4\n",
      "Extracting faces for 1941250_E_003.mp4\n",
      "Extracting faces for 1941250_A_003.mp4\n",
      "Extracting faces for 1941250_I_003.mp4\n",
      "Extracting faces for 1941250_J_001.mp4\n",
      "Extracting faces for 1941250_F_001.mp4\n",
      "Extracting faces for 1941250_B_001.mp4\n",
      "Extracting faces for 1941250_H_003.mp4\n",
      "Extracting faces for 1941250_D_003.mp4\n",
      "Extracting faces for 1941250_G_001.mp4\n",
      "Extracting faces for 1941250_C_001.mp4\n",
      "Extracting faces for 1941250_I_002.mp4\n",
      "Extracting faces for 1941250_E_002.mp4\n",
      "Extracting faces for 1941250_A_002.mp4\n",
      "Extracting faces for 1501828_A_002.mp4\n",
      "Extracting faces for 1501828_A_003.mp4\n",
      "Extracting faces for 1501828_A_001.mp4\n",
      "Extracting faces for 1152039_E_002.mp4\n",
      "Extracting faces for 1152039_A_002.mp4\n",
      "Extracting faces for 1152039_C_001.mp4\n",
      "Extracting faces for 1152039_D_003.mp4\n",
      "Extracting faces for 1152039_B_001.mp4\n",
      "Extracting faces for 1152039_E_003.mp4\n",
      "Extracting faces for 1152039_A_003.mp4\n",
      "Extracting faces for 1152039_D_002.mp4\n",
      "Extracting faces for 1152039_D_001.mp4\n",
      "Extracting faces for 1152039_C_003.mp4\n",
      "Extracting faces for 1152039_B_002.mp4\n",
      "Extracting faces for 1152039_C_002.mp4\n",
      "Extracting faces for 1152039_E_001.mp4\n",
      "Extracting faces for 1152039_A_001.mp4\n",
      "Extracting faces for 1152039_B_003.mp4\n",
      "Extracting faces for 1061402_B_001.mp4\n",
      "Extracting faces for 1061402_E_003.mp4\n",
      "Extracting faces for 1061402_A_003.mp4\n",
      "Extracting faces for 1061402_D_002.mp4\n",
      "Extracting faces for 1061402_E_002.mp4\n",
      "Extracting faces for 1061402_A_002.mp4\n",
      "Extracting faces for 1061402_C_001.mp4\n",
      "Extracting faces for 1061402_D_003.mp4\n",
      "Extracting faces for 1061402_C_002.mp4\n",
      "Extracting faces for 1061402_E_001.mp4\n",
      "Extracting faces for 1061402_A_001.mp4\n",
      "Extracting faces for 1061402_B_003.mp4\n",
      "Extracting faces for 1061402_D_001.mp4\n",
      "Extracting faces for 1061402_C_003.mp4\n",
      "Extracting faces for 1061402_B_002.mp4\n",
      "Extracting faces for 804259_G_002.mp4\n",
      "Extracting faces for 804259_C_002.mp4\n",
      "Extracting faces for 804259_J_003.mp4\n",
      "Extracting faces for 804259_F_003.mp4\n",
      "Extracting faces for 804259_B_003.mp4\n",
      "Extracting faces for 804259_E_001.mp4\n",
      "Extracting faces for 804259_A_001.mp4\n",
      "Extracting faces for 804259_I_001.mp4\n",
      "Extracting faces for 804259_G_003.mp4\n",
      "Extracting faces for 804259_C_003.mp4\n",
      "Extracting faces for 804259_H_001.mp4\n",
      "Extracting faces for 804259_D_001.mp4\n",
      "Extracting faces for 804259_F_002.mp4\n",
      "Extracting faces for 804259_B_002.mp4\n",
      "Extracting faces for 804259_J_002.mp4\n",
      "Extracting faces for 804259_E_003.mp4\n",
      "Extracting faces for 804259_A_003.mp4\n",
      "Extracting faces for 804259_I_003.mp4\n",
      "Extracting faces for 804259_J_001.mp4\n",
      "Extracting faces for 804259_F_001.mp4\n",
      "Extracting faces for 804259_B_001.mp4\n",
      "Extracting faces for 804259_D_002.mp4\n",
      "Extracting faces for 804259_H_002.mp4\n",
      "Extracting faces for 804259_I_002.mp4\n",
      "Extracting faces for 804259_E_002.mp4\n",
      "Extracting faces for 804259_A_002.mp4\n",
      "Extracting faces for 804259_H_003.mp4\n",
      "Extracting faces for 804259_D_003.mp4\n",
      "Extracting faces for 804259_G_001.mp4\n",
      "Extracting faces for 804259_C_001.mp4\n",
      "Extracting faces for 2104983_B_002.mp4\n",
      "Extracting faces for 2104983_C_003.mp4\n",
      "Extracting faces for 2104983_A_001.mp4\n",
      "Extracting faces for 2104983_B_003.mp4\n",
      "Extracting faces for 2104983_C_002.mp4\n",
      "Extracting faces for 2104983_C_001.mp4\n",
      "Extracting faces for 2104983_A_002.mp4\n",
      "Extracting faces for 2104983_B_001.mp4\n",
      "Extracting faces for 2104983_A_003.mp4\n",
      "Extracting faces for 1290777_B_002.mp4\n",
      "Extracting faces for 1290777_C_003.mp4\n",
      "Extracting faces for 1290777_A_001.mp4\n",
      "Extracting faces for 1290777_B_003.mp4\n",
      "Extracting faces for 1290777_C_002.mp4\n",
      "Extracting faces for 1290777_C_001.mp4\n",
      "Extracting faces for 1290777_A_002.mp4\n",
      "Extracting faces for 1290777_B_001.mp4\n",
      "Extracting faces for 1290777_A_003.mp4\n",
      "Extracting faces for 2005778_D_002.mp4\n",
      "Extracting faces for 2005778_H_002.mp4\n",
      "Extracting faces for 2005778_L_002.mp4\n",
      "Extracting faces for 2005778_E_003.mp4\n",
      "Extracting faces for 2005778_A_003.mp4\n",
      "Extracting faces for 2005778_I_003.mp4\n",
      "Extracting faces for 2005778_M_003.mp4\n",
      "Extracting faces for 2005778_J_001.mp4\n",
      "Extracting faces for 2005778_F_001.mp4\n",
      "Extracting faces for 2005778_B_001.mp4\n",
      "Extracting faces for 2005778_H_003.mp4\n",
      "Extracting faces for 2005778_L_003.mp4\n",
      "Extracting faces for 2005778_D_003.mp4\n",
      "Extracting faces for 2005778_G_001.mp4\n",
      "Extracting faces for 2005778_C_001.mp4\n",
      "Extracting faces for 2005778_K_001.mp4\n",
      "Extracting faces for 2005778_I_002.mp4\n",
      "Extracting faces for 2005778_M_002.mp4\n",
      "Extracting faces for 2005778_E_002.mp4\n",
      "Extracting faces for 2005778_A_002.mp4\n",
      "Extracting faces for 2005778_J_003.mp4\n",
      "Extracting faces for 2005778_F_003.mp4\n",
      "Extracting faces for 2005778_B_003.mp4\n",
      "Extracting faces for 2005778_E_001.mp4\n",
      "Extracting faces for 2005778_A_001.mp4\n",
      "Extracting faces for 2005778_I_001.mp4\n",
      "Extracting faces for 2005778_M_001.mp4\n",
      "Extracting faces for 2005778_K_002.mp4\n",
      "Extracting faces for 2005778_G_002.mp4\n",
      "Extracting faces for 2005778_C_002.mp4\n",
      "Extracting faces for 2005778_F_002.mp4\n",
      "Extracting faces for 2005778_B_002.mp4\n",
      "Extracting faces for 2005778_J_002.mp4\n",
      "Extracting faces for 2005778_G_003.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting faces for 2005778_C_003.mp4\n",
      "Extracting faces for 2005778_K_003.mp4\n",
      "Extracting faces for 2005778_H_001.mp4\n",
      "Extracting faces for 2005778_L_001.mp4\n",
      "Extracting faces for 2005778_D_001.mp4\n",
      "Extracting faces for 1059855_I_003.mp4\n",
      "Extracting faces for 1059855_E_003.mp4\n",
      "Extracting faces for 1059855_A_003.mp4\n",
      "Extracting faces for 1059855_F_001.mp4\n",
      "Extracting faces for 1059855_B_001.mp4\n",
      "Extracting faces for 1059855_H_002.mp4\n",
      "Extracting faces for 1059855_D_002.mp4\n",
      "Extracting faces for 1059855_E_002.mp4\n",
      "Extracting faces for 1059855_A_002.mp4\n",
      "Extracting faces for 1059855_I_002.mp4\n",
      "Extracting faces for 1059855_D_003.mp4\n",
      "Extracting faces for 1059855_H_003.mp4\n",
      "Extracting faces for 1059855_G_001.mp4\n",
      "Extracting faces for 1059855_C_001.mp4\n",
      "Extracting faces for 1059855_G_002.mp4\n",
      "Extracting faces for 1059855_C_002.mp4\n",
      "Extracting faces for 1059855_F_003.mp4\n",
      "Extracting faces for 1059855_B_003.mp4\n",
      "Extracting faces for 1059855_I_001.mp4\n",
      "Extracting faces for 1059855_E_001.mp4\n",
      "Extracting faces for 1059855_A_001.mp4\n",
      "Extracting faces for 1059855_G_003.mp4\n",
      "Extracting faces for 1059855_C_003.mp4\n",
      "Extracting faces for 1059855_D_001.mp4\n",
      "Extracting faces for 1059855_H_001.mp4\n",
      "Extracting faces for 1059855_F_002.mp4\n",
      "Extracting faces for 1059855_B_002.mp4\n",
      "Extracting faces for 1783597_J_002.mp4\n",
      "Extracting faces for 1783597_B_002.mp4\n",
      "Extracting faces for 1783597_F_002.mp4\n",
      "Extracting faces for 1783597_C_003.mp4\n",
      "Extracting faces for 1783597_G_003.mp4\n",
      "Extracting faces for 1783597_D_001.mp4\n",
      "Extracting faces for 1783597_H_001.mp4\n",
      "Extracting faces for 1783597_B_003.mp4\n",
      "Extracting faces for 1783597_F_003.mp4\n",
      "Extracting faces for 1783597_J_003.mp4\n",
      "Extracting faces for 1783597_I_001.mp4\n",
      "Extracting faces for 1783597_A_001.mp4\n",
      "Extracting faces for 1783597_E_001.mp4\n",
      "Extracting faces for 1783597_C_002.mp4\n",
      "Extracting faces for 1783597_G_002.mp4\n",
      "Extracting faces for 1783597_D_003.mp4\n",
      "Extracting faces for 1783597_H_003.mp4\n",
      "Extracting faces for 1783597_C_001.mp4\n",
      "Extracting faces for 1783597_G_001.mp4\n",
      "Extracting faces for 1783597_A_002.mp4\n",
      "Extracting faces for 1783597_E_002.mp4\n",
      "Extracting faces for 1783597_I_002.mp4\n",
      "Extracting faces for 1783597_H_002.mp4\n",
      "Extracting faces for 1783597_D_002.mp4\n",
      "Extracting faces for 1783597_I_003.mp4\n",
      "Extracting faces for 1783597_A_003.mp4\n",
      "Extracting faces for 1783597_E_003.mp4\n",
      "Extracting faces for 1783597_B_001.mp4\n",
      "Extracting faces for 1783597_F_001.mp4\n",
      "Extracting faces for 1783597_J_001.mp4\n",
      "Extracting faces for 1993279_A_001.mp4\n",
      "Extracting faces for 1993279_A_002.mp4\n",
      "Extracting faces for 1993279_A_003.mp4\n",
      "Extracting faces for 1733757_D_003.mp4\n",
      "Extracting faces for 1733757_C_001.mp4\n",
      "Extracting faces for 1733757_A_002.mp4\n",
      "Extracting faces for 1733757_D_002.mp4\n",
      "Extracting faces for 1733757_A_003.mp4\n",
      "Extracting faces for 1733757_B_001.mp4\n",
      "Extracting faces for 1733757_B_002.mp4\n",
      "Extracting faces for 1733757_C_003.mp4\n",
      "Extracting faces for 1733757_D_001.mp4\n",
      "Extracting faces for 1733757_B_003.mp4\n",
      "Extracting faces for 1733757_A_001.mp4\n",
      "Extracting faces for 1733757_C_002.mp4\n",
      "Extracting faces for 2059294_B_003.mp4\n",
      "Extracting faces for 2059294_A_001.mp4\n",
      "Extracting faces for 2059294_B_002.mp4\n",
      "Extracting faces for 2059294_A_003.mp4\n",
      "Extracting faces for 2059294_B_001.mp4\n",
      "Extracting faces for 2059294_A_002.mp4\n",
      "Extracting faces for 1997643_D_002.mp4\n",
      "Extracting faces for 1997643_H_002.mp4\n",
      "Extracting faces for 1997643_J_001.mp4\n",
      "Extracting faces for 1997643_B_001.mp4\n",
      "Extracting faces for 1997643_F_001.mp4\n",
      "Extracting faces for 1997643_A_003.mp4\n",
      "Extracting faces for 1997643_E_003.mp4\n",
      "Extracting faces for 1997643_I_003.mp4\n",
      "Extracting faces for 1997643_C_001.mp4\n",
      "Extracting faces for 1997643_G_001.mp4\n",
      "Extracting faces for 1997643_H_003.mp4\n",
      "Extracting faces for 1997643_D_003.mp4\n",
      "Extracting faces for 1997643_I_002.mp4\n",
      "Extracting faces for 1997643_A_002.mp4\n",
      "Extracting faces for 1997643_E_002.mp4\n",
      "Extracting faces for 1997643_A_001.mp4\n",
      "Extracting faces for 1997643_E_001.mp4\n",
      "Extracting faces for 1997643_I_001.mp4\n",
      "Extracting faces for 1997643_J_003.mp4\n",
      "Extracting faces for 1997643_B_003.mp4\n",
      "Extracting faces for 1997643_F_003.mp4\n",
      "Extracting faces for 1997643_C_002.mp4\n",
      "Extracting faces for 1997643_G_002.mp4\n",
      "Extracting faces for 1997643_B_002.mp4\n",
      "Extracting faces for 1997643_F_002.mp4\n",
      "Extracting faces for 1997643_J_002.mp4\n",
      "Extracting faces for 1997643_H_001.mp4\n",
      "Extracting faces for 1997643_D_001.mp4\n",
      "Extracting faces for 1997643_C_003.mp4\n",
      "Extracting faces for 1997643_G_003.mp4\n",
      "Extracting faces for 2084869_D_002.mp4\n",
      "Extracting faces for 2084869_A_003.mp4\n",
      "Extracting faces for 2084869_E_003.mp4\n",
      "Extracting faces for 2084869_B_001.mp4\n",
      "Extracting faces for 2084869_D_003.mp4\n",
      "Extracting faces for 2084869_C_001.mp4\n",
      "Extracting faces for 2084869_A_002.mp4\n",
      "Extracting faces for 2084869_E_002.mp4\n",
      "Extracting faces for 2084869_B_003.mp4\n",
      "Extracting faces for 2084869_A_001.mp4\n",
      "Extracting faces for 2084869_E_001.mp4\n",
      "Extracting faces for 2084869_C_002.mp4\n",
      "Extracting faces for 2084869_B_002.mp4\n",
      "Extracting faces for 2084869_C_003.mp4\n",
      "Extracting faces for 2084869_D_001.mp4\n",
      "Extracting faces for 1677632_C_002.mp4\n",
      "Extracting faces for 1677632_B_003.mp4\n",
      "Extracting faces for 1677632_F_003.mp4\n",
      "Extracting faces for 1677632_A_001.mp4\n",
      "Extracting faces for 1677632_E_001.mp4\n",
      "Extracting faces for 1677632_C_003.mp4\n",
      "Extracting faces for 1677632_D_001.mp4\n",
      "Extracting faces for 1677632_B_002.mp4\n",
      "Extracting faces for 1677632_F_002.mp4\n",
      "Extracting faces for 1677632_A_003.mp4\n",
      "Extracting faces for 1677632_E_003.mp4\n",
      "Extracting faces for 1677632_B_001.mp4\n",
      "Extracting faces for 1677632_F_001.mp4\n",
      "Extracting faces for 1677632_D_002.mp4\n",
      "Extracting faces for 1677632_A_002.mp4\n",
      "Extracting faces for 1677632_E_002.mp4\n",
      "Extracting faces for 1677632_D_003.mp4\n",
      "Extracting faces for 1677632_C_001.mp4\n",
      "Extracting faces for 1600085_C_003.mp4\n",
      "Extracting faces for 1600085_B_002.mp4\n",
      "Extracting faces for 1600085_C_002.mp4\n",
      "Extracting faces for 1600085_B_003.mp4\n",
      "Extracting faces for 1600085_A_001.mp4\n",
      "Extracting faces for 1600085_A_002.mp4\n",
      "Extracting faces for 1600085_C_001.mp4\n",
      "Extracting faces for 1600085_A_003.mp4\n",
      "Extracting faces for 1600085_B_001.mp4\n",
      "Extracting faces for 1916010_H_002.mp4\n",
      "Extracting faces for 1916010_D_002.mp4\n",
      "Extracting faces for 1916010_I_003.mp4\n",
      "Extracting faces for 1916010_E_003.mp4\n",
      "Extracting faces for 1916010_A_003.mp4\n",
      "Extracting faces for 1916010_F_001.mp4\n",
      "Extracting faces for 1916010_B_001.mp4\n",
      "Extracting faces for 1916010_J_001.mp4\n",
      "Extracting faces for 1916010_D_003.mp4\n",
      "Extracting faces for 1916010_H_003.mp4\n",
      "Extracting faces for 1916010_G_001.mp4\n",
      "Extracting faces for 1916010_C_001.mp4\n",
      "Extracting faces for 1916010_E_002.mp4\n",
      "Extracting faces for 1916010_A_002.mp4\n",
      "Extracting faces for 1916010_I_002.mp4\n",
      "Extracting faces for 1916010_F_003.mp4\n",
      "Extracting faces for 1916010_B_003.mp4\n",
      "Extracting faces for 1916010_J_003.mp4\n",
      "Extracting faces for 1916010_I_001.mp4\n",
      "Extracting faces for 1916010_E_001.mp4\n",
      "Extracting faces for 1916010_A_001.mp4\n",
      "Extracting faces for 1916010_G_002.mp4\n",
      "Extracting faces for 1916010_C_002.mp4\n",
      "Extracting faces for 1916010_J_002.mp4\n",
      "Extracting faces for 1916010_F_002.mp4\n",
      "Extracting faces for 1916010_B_002.mp4\n",
      "Extracting faces for 1916010_G_003.mp4\n",
      "Extracting faces for 1916010_C_003.mp4\n",
      "Extracting faces for 1916010_D_001.mp4\n",
      "Extracting faces for 1916010_H_001.mp4\n",
      "Extracting faces for 1690464_C_002.mp4\n",
      "Extracting faces for 1690464_G_002.mp4\n",
      "Extracting faces for 1690464_A_001.mp4\n",
      "Extracting faces for 1690464_E_001.mp4\n",
      "Extracting faces for 1690464_B_003.mp4\n",
      "Extracting faces for 1690464_F_003.mp4\n",
      "Extracting faces for 1690464_D_001.mp4\n",
      "Extracting faces for 1690464_H_001.mp4\n",
      "Extracting faces for 1690464_C_003.mp4\n",
      "Extracting faces for 1690464_G_003.mp4\n",
      "Extracting faces for 1690464_B_002.mp4\n",
      "Extracting faces for 1690464_F_002.mp4\n",
      "Extracting faces for 1690464_B_001.mp4\n",
      "Extracting faces for 1690464_F_001.mp4\n",
      "Extracting faces for 1690464_A_003.mp4\n",
      "Extracting faces for 1690464_E_003.mp4\n",
      "Extracting faces for 1690464_H_002.mp4\n",
      "Extracting faces for 1690464_D_002.mp4\n",
      "Extracting faces for 1690464_A_002.mp4\n",
      "Extracting faces for 1690464_E_002.mp4\n",
      "Extracting faces for 1690464_C_001.mp4\n",
      "Extracting faces for 1690464_G_001.mp4\n",
      "Extracting faces for 1690464_D_003.mp4\n",
      "Extracting faces for 1690464_H_003.mp4\n",
      "Extracting faces for 2076328_F_001.mp4\n",
      "Extracting faces for 2076328_B_001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting faces for 2076328_E_003.mp4\n",
      "Extracting faces for 2076328_A_003.mp4\n",
      "Extracting faces for 2076328_D_002.mp4\n",
      "Extracting faces for 2076328_E_002.mp4\n",
      "Extracting faces for 2076328_A_002.mp4\n",
      "Extracting faces for 2076328_G_001.mp4\n",
      "Extracting faces for 2076328_C_001.mp4\n",
      "Extracting faces for 2076328_D_003.mp4\n",
      "Extracting faces for 2076328_G_002.mp4\n",
      "Extracting faces for 2076328_C_002.mp4\n",
      "Extracting faces for 2076328_E_001.mp4\n",
      "Extracting faces for 2076328_A_001.mp4\n",
      "Extracting faces for 2076328_F_003.mp4\n",
      "Extracting faces for 2076328_B_003.mp4\n",
      "Extracting faces for 2076328_D_001.mp4\n",
      "Extracting faces for 2076328_G_003.mp4\n",
      "Extracting faces for 2076328_C_003.mp4\n",
      "Extracting faces for 2076328_F_002.mp4\n",
      "Extracting faces for 2076328_B_002.mp4\n",
      "Extracting faces for 2011804_C_001.mp4\n",
      "Extracting faces for 2011804_A_002.mp4\n",
      "Extracting faces for 2011804_B_001.mp4\n",
      "Extracting faces for 2011804_A_003.mp4\n",
      "Extracting faces for 2011804_B_002.mp4\n",
      "Extracting faces for 2011804_C_003.mp4\n",
      "Extracting faces for 2011804_A_001.mp4\n",
      "Extracting faces for 2011804_B_003.mp4\n",
      "Extracting faces for 2011804_C_002.mp4\n",
      "Extracting faces for 1390015_A_003.mp4\n",
      "Extracting faces for 1390015_A_002.mp4\n",
      "Extracting faces for 1390015_A_001.mp4\n",
      "Extracting faces for 1922507_B_001.mp4\n",
      "Extracting faces for 1922507_A_003.mp4\n",
      "Extracting faces for 1922507_C_001.mp4\n",
      "Extracting faces for 1922507_A_002.mp4\n",
      "Extracting faces for 1922507_A_001.mp4\n",
      "Extracting faces for 1922507_B_003.mp4\n",
      "Extracting faces for 1922507_C_002.mp4\n",
      "Extracting faces for 1922507_B_002.mp4\n",
      "Extracting faces for 1922507_C_003.mp4\n",
      "Extracting faces for 1782722_D_002.mp4\n",
      "Extracting faces for 1782722_B_001.mp4\n",
      "Extracting faces for 1782722_A_003.mp4\n",
      "Extracting faces for 1782722_C_001.mp4\n",
      "Extracting faces for 1782722_D_003.mp4\n",
      "Extracting faces for 1782722_A_002.mp4\n",
      "Extracting faces for 1782722_A_001.mp4\n",
      "Extracting faces for 1782722_B_003.mp4\n",
      "Extracting faces for 1782722_C_002.mp4\n",
      "Extracting faces for 1782722_B_002.mp4\n",
      "Extracting faces for 1782722_D_001.mp4\n",
      "Extracting faces for 1782722_C_003.mp4\n",
      "Extracting faces for 1822940_D_002.mp4\n",
      "Extracting faces for 1822940_H_002.mp4\n",
      "Extracting faces for 1822940_A_003.mp4\n",
      "Extracting faces for 1822940_E_003.mp4\n",
      "Extracting faces for 1822940_I_003.mp4\n",
      "Extracting faces for 1822940_B_001.mp4\n",
      "Extracting faces for 1822940_F_001.mp4\n",
      "Extracting faces for 1822940_H_003.mp4\n",
      "Extracting faces for 1822940_D_003.mp4\n",
      "Extracting faces for 1822940_C_001.mp4\n",
      "Extracting faces for 1822940_G_001.mp4\n",
      "Extracting faces for 1822940_I_002.mp4\n",
      "Extracting faces for 1822940_A_002.mp4\n",
      "Extracting faces for 1822940_E_002.mp4\n",
      "Extracting faces for 1822940_B_003.mp4\n",
      "Extracting faces for 1822940_F_003.mp4\n",
      "Extracting faces for 1822940_A_001.mp4\n",
      "Extracting faces for 1822940_E_001.mp4\n",
      "Extracting faces for 1822940_I_001.mp4\n",
      "Extracting faces for 1822940_C_002.mp4\n",
      "Extracting faces for 1822940_G_002.mp4\n",
      "Extracting faces for 1822940_B_002.mp4\n",
      "Extracting faces for 1822940_F_002.mp4\n",
      "Extracting faces for 1822940_C_003.mp4\n",
      "Extracting faces for 1822940_G_003.mp4\n",
      "Extracting faces for 1822940_H_001.mp4\n",
      "Extracting faces for 1822940_D_001.mp4\n",
      "Extracting faces for 1853436_E_002.mp4\n",
      "Extracting faces for 1853436_A_002.mp4\n",
      "Extracting faces for 1853436_C_001.mp4\n",
      "Extracting faces for 1853436_D_003.mp4\n",
      "Extracting faces for 1853436_F_001.mp4\n",
      "Extracting faces for 1853436_B_001.mp4\n",
      "Extracting faces for 1853436_E_003.mp4\n",
      "Extracting faces for 1853436_A_003.mp4\n",
      "Extracting faces for 1853436_D_002.mp4\n",
      "Extracting faces for 1853436_D_001.mp4\n",
      "Extracting faces for 1853436_C_003.mp4\n",
      "Extracting faces for 1853436_F_002.mp4\n",
      "Extracting faces for 1853436_B_002.mp4\n",
      "Extracting faces for 1853436_C_002.mp4\n",
      "Extracting faces for 1853436_E_001.mp4\n",
      "Extracting faces for 1853436_A_001.mp4\n",
      "Extracting faces for 1853436_F_003.mp4\n",
      "Extracting faces for 1853436_B_003.mp4\n",
      "Extracting faces for 1260311_B_002.mp4\n",
      "Extracting faces for 1260311_F_002.mp4\n",
      "Extracting faces for 1260311_C_003.mp4\n",
      "Extracting faces for 1260311_G_003.mp4\n",
      "Extracting faces for 1260311_D_001.mp4\n",
      "Extracting faces for 1260311_H_001.mp4\n",
      "Extracting faces for 1260311_B_003.mp4\n",
      "Extracting faces for 1260311_F_003.mp4\n",
      "Extracting faces for 1260311_I_001.mp4\n",
      "Extracting faces for 1260311_A_001.mp4\n",
      "Extracting faces for 1260311_E_001.mp4\n",
      "Extracting faces for 1260311_C_002.mp4\n",
      "Extracting faces for 1260311_G_002.mp4\n",
      "Extracting faces for 1260311_D_003.mp4\n",
      "Extracting faces for 1260311_H_003.mp4\n",
      "Extracting faces for 1260311_C_001.mp4\n",
      "Extracting faces for 1260311_G_001.mp4\n",
      "Extracting faces for 1260311_A_002.mp4\n",
      "Extracting faces for 1260311_E_002.mp4\n",
      "Extracting faces for 1260311_I_002.mp4\n",
      "Extracting faces for 1260311_H_002.mp4\n",
      "Extracting faces for 1260311_D_002.mp4\n",
      "Extracting faces for 1260311_I_003.mp4\n",
      "Extracting faces for 1260311_A_003.mp4\n",
      "Extracting faces for 1260311_E_003.mp4\n",
      "Extracting faces for 1260311_B_001.mp4\n",
      "Extracting faces for 1260311_F_001.mp4\n",
      "Extracting faces for 643049_C_003.mp4\n",
      "Extracting faces for 643049_D_001.mp4\n",
      "Extracting faces for 643049_B_002.mp4\n",
      "Extracting faces for 643049_C_002.mp4\n",
      "Extracting faces for 643049_B_003.mp4\n",
      "Extracting faces for 643049_E_001.mp4\n",
      "Extracting faces for 643049_A_001.mp4\n",
      "Extracting faces for 643049_E_002.mp4\n",
      "Extracting faces for 643049_A_002.mp4\n",
      "Extracting faces for 643049_D_003.mp4\n",
      "Extracting faces for 643049_C_001.mp4\n",
      "Extracting faces for 643049_E_003.mp4\n",
      "Extracting faces for 643049_A_003.mp4\n",
      "Extracting faces for 643049_B_001.mp4\n",
      "Extracting faces for 643049_D_002.mp4\n",
      "Extracting faces for 1609928_B_002.mp4\n",
      "Extracting faces for 1609928_C_003.mp4\n",
      "Extracting faces for 1609928_D_001.mp4\n",
      "Extracting faces for 1609928_B_003.mp4\n",
      "Extracting faces for 1609928_E_001.mp4\n",
      "Extracting faces for 1609928_A_001.mp4\n",
      "Extracting faces for 1609928_C_002.mp4\n",
      "Extracting faces for 1609928_D_003.mp4\n",
      "Extracting faces for 1609928_C_001.mp4\n",
      "Extracting faces for 1609928_E_002.mp4\n",
      "Extracting faces for 1609928_A_002.mp4\n",
      "Extracting faces for 1609928_D_002.mp4\n",
      "Extracting faces for 1609928_E_003.mp4\n",
      "Extracting faces for 1609928_A_003.mp4\n",
      "Extracting faces for 1609928_B_001.mp4\n",
      "Extracting faces for 1262961_F_002.mp4\n",
      "Extracting faces for 1262961_B_002.mp4\n",
      "Extracting faces for 1262961_C_003.mp4\n",
      "Extracting faces for 1262961_D_001.mp4\n",
      "Extracting faces for 1262961_F_003.mp4\n",
      "Extracting faces for 1262961_B_003.mp4\n",
      "Extracting faces for 1262961_E_001.mp4\n",
      "Extracting faces for 1262961_A_001.mp4\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "#--- Author         : Ahmet Ozlu\n",
    "#--- Mail           : ahmetozlu93@gmail.com\n",
    "#--- Date           : 21st September 2017\n",
    "#----------------------------------------------\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "import ffmpeg\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "sys.path.append(\"../face_recognition_crop/utils/\")\n",
    "# import create_csv\n",
    "\n",
    "\n",
    "def extract_face_from_vid(video, output_path='', m=128, show=False):\n",
    "\n",
    "    if not os.path.isdir(video):\n",
    "        # Open the input movie file\n",
    "        input_movie = cv2.VideoCapture(video)\n",
    "        length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    else:\n",
    "        frame_list = [f for f in os.listdir(video) if f.endswith('.jpg')]\n",
    "\n",
    "    # Initialize some variables\n",
    "    frame_number = 0\n",
    "    current_path = os.getcwd()\n",
    "\n",
    "    while True:\n",
    "        # Grab next frame\n",
    "        if os.path.isdir(video):\n",
    "            if frame_number>=len(frame_list):\n",
    "                break\n",
    "            frame = cv2.imread(os.path.join(video, frame_list[frame_number]))\n",
    "        else:\n",
    "            # Grab a single frame of video\n",
    "            ret, frame = input_movie.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "        frame_number += 1\n",
    "        \n",
    "        if not frame_number % 2: continue\n",
    "            \n",
    "        if frame_number>50:\n",
    "            break\n",
    "            \n",
    "        start = timer()\n",
    "            \n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(frame, number_of_times_to_upsample=0, model='cnn')\n",
    "#         face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "        end = timer()\n",
    "#         print(\"Time extracting face loc:\", end-start)\n",
    "\n",
    "        # Label the results\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "\n",
    "            \n",
    "            if m < 1:\n",
    "                m = (bottom-top)//2 + int((bottom-top)*m)\n",
    "                cx = left+(right-left)//2\n",
    "                cy = top+(bottom-top)//2\n",
    "                crop_img = frame[cy-m:cy+m, cx-m:cx+m]   \n",
    "            else:\n",
    "                cx = left+(right-left)//2\n",
    "                cy = top+(bottom-top)//2\n",
    "                crop_img = frame[cy-m:cy+m, cx-m:cx+m]            \n",
    "            os.makedirs(os.path.join(output_path, os.path.basename(video)), exist_ok=True)\n",
    "            cv2.imwrite(os.path.join(output_path, os.path.basename(video), '%05d.jpg' % (frame_number-1)), crop_img)\n",
    "\n",
    "        if show:\n",
    "            plt.imshow(crop_img[:,:,::-1])\n",
    "            plt.show()\n",
    "\n",
    "    # All done!\n",
    "    if not os.path.isdir(video): input_movie.release()\n",
    "#     create_csv.CreateCsv(current_path + \"/face_database/\")\n",
    "\n",
    "\n",
    "def extract_faces_parallel(video_root, output_path, num_threads=100):\n",
    "    \"\"\"Extracts faces from video in a parallel fashion.\"\"\"\n",
    "\n",
    "    videos = []\n",
    "    for r, d, f in os.walk(video_root):\n",
    "        for file in f:\n",
    "            if '.mp4' in file:\n",
    "                videos.append(os.path.join(r, file))\n",
    "#     print(videos)\n",
    "\n",
    "#     mp.set_start_method('spawn')\n",
    "    \n",
    "    func = functools.partial(extract_face_from_vid, output_path=output_path, m=0.3, show=False)\n",
    "    pool = Pool(num_threads)\n",
    "    pool.map(func, videos)\n",
    "    \n",
    "def extract_faces(video_root, output_path):\n",
    "    videos = []\n",
    "    for r, d, f in os.walk(video_root):\n",
    "        for file in f:\n",
    "            if '.mp4' in file:\n",
    "                print(\"Extracting faces for\", file)\n",
    "#                 if not os.path.exists(os.path.join(output_path, file)):\n",
    "                extract_face_from_vid(os.path.join(r, file), output_path=output_path)\n",
    "                \n",
    "extract_faces('../../deepfake_data/fb_dfd_release_0.1_final/original_videos', \n",
    "                '../../deepfake_data/fb_dfd_release_0.1_final/original_videos_crops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644.0674523357302\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "# extract_face_from_vid('../../deepfake_data/fb_dfd_release_0.1_final/method_A/1681757/1681757_D/2076328_1681757_D_001.mp4',\n",
    "#                      output_path='../../deepfake_data/fb_dfd_release_0.1_final/method_A_crops',show=True)\n",
    "\n",
    "extract_face_from_vid('../../deepfake_data/fb_dfd_release_0.1_final/method_A_frames/1974002_1061402_B_003.mp4',\n",
    "                     output_path='../../deepfake_data/fb_dfd_release_0.1_final/method_A_crops',show=False)\n",
    "\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605.4667557608336\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "extract_face_from_vid('../../deepfake_data/fb_dfd_release_0.1_final/method_A/1061402/1061402_B/1974002_1061402_B_003.mp4',\n",
    "                     output_path='../../deepfake_data/fb_dfd_release_0.1_final/method_A_crops',show=False)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import dlib.cuda as cuda\n",
    "print(cuda.get_num_devices())\n",
    "print(dlib.DLIB_USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-python3",
   "language": "python",
   "name": "tf-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
